{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-15T08:03:52.627252Z",
     "iopub.status.busy": "2024-12-15T08:03:52.626883Z",
     "iopub.status.idle": "2024-12-15T08:05:05.558891Z",
     "shell.execute_reply": "2024-12-15T08:05:05.557392Z",
     "shell.execute_reply.started": "2024-12-15T08:03:52.627218Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting inference\n",
      "  Downloading inference-0.31.1-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting aiortc<2.0.0,>=1.9.0 (from inference)\n",
      "  Downloading aiortc-1.9.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
      "Collecting APScheduler<4.0.0,>=3.10.1 (from inference)\n",
      "  Downloading APScheduler-3.11.0-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting asyncua~=1.1.5 (from inference)\n",
      "  Downloading asyncua-1.1.5-py3-none-any.whl.metadata (9.5 kB)\n",
      "Requirement already satisfied: cython~=3.0.0 in /opt/conda/lib/python3.10/site-packages (from inference) (3.0.10)\n",
      "Requirement already satisfied: python-dotenv~=1.0.0 in /opt/conda/lib/python3.10/site-packages (from inference) (1.0.1)\n",
      "Collecting fastapi<0.111,>=0.100 (from inference)\n",
      "  Downloading fastapi-0.110.3-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: numpy<=1.26.4 in /opt/conda/lib/python3.10/site-packages (from inference) (1.26.4)\n",
      "Requirement already satisfied: opencv-python<=4.10.0.84,>=4.8.1.78 in /opt/conda/lib/python3.10/site-packages (from inference) (4.10.0.84)\n",
      "Requirement already satisfied: pillow<11.0 in /opt/conda/lib/python3.10/site-packages (from inference) (10.3.0)\n",
      "Collecting prometheus-fastapi-instrumentator<=6.0.0 (from inference)\n",
      "  Downloading prometheus_fastapi_instrumentator-6.0.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting redis~=5.0.0 (from inference)\n",
      "  Downloading redis-5.0.8-py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.32.0 in /opt/conda/lib/python3.10/site-packages (from inference) (2.32.3)\n",
      "Requirement already satisfied: rich<13.10.0,>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from inference) (13.7.1)\n",
      "Collecting supervision<=0.30.0,>=0.25.1 (from inference)\n",
      "  Downloading supervision-0.25.1-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting pybase64~=1.0.0 (from inference)\n",
      "  Downloading pybase64-1.0.2.tar.gz (105 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.7/105.7 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: scikit-image<=0.24.0,>=0.19.0 in /opt/conda/lib/python3.10/site-packages (from inference) (0.23.2)\n",
      "Collecting requests-toolbelt~=1.0.0 (from inference)\n",
      "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: wheel<=0.45.0,>=0.38.1 in /opt/conda/lib/python3.10/site-packages (from inference) (0.43.0)\n",
      "Requirement already satisfied: setuptools>=70.0.0 in /opt/conda/lib/python3.10/site-packages (from inference) (70.0.0)\n",
      "Requirement already satisfied: networkx~=3.1 in /opt/conda/lib/python3.10/site-packages (from inference) (3.3)\n",
      "Requirement already satisfied: pydantic~=2.6 in /opt/conda/lib/python3.10/site-packages (from inference) (2.10.2)\n",
      "Collecting pydantic-settings~=2.2 (from inference)\n",
      "  Downloading pydantic_settings-2.7.0-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting openai<2.0.0,>=1.12.0 (from inference)\n",
      "  Downloading openai-1.57.4-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting structlog<25.0.0,>=24.1.0 (from inference)\n",
      "  Downloading structlog-24.4.0-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting zxing-cpp~=2.2.0 (from inference)\n",
      "  Downloading zxing_cpp-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.9 kB)\n",
      "Requirement already satisfied: boto3<=1.35.60 in /opt/conda/lib/python3.10/site-packages (from inference) (1.26.100)\n",
      "Requirement already satisfied: typing_extensions<=4.12.2,>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from inference) (4.12.2)\n",
      "Collecting pydot~=2.0.0 (from inference)\n",
      "  Downloading pydot-2.0.0-py3-none-any.whl.metadata (9.6 kB)\n",
      "Collecting shapely<2.1.0,>=2.0.0 (from inference)\n",
      "  Downloading shapely-2.0.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.0 kB)\n",
      "Collecting tldextract~=5.1.2 (from inference)\n",
      "  Downloading tldextract-5.1.3-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting packaging~=24.0 (from inference)\n",
      "  Downloading packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting anthropic~=0.34.2 (from inference)\n",
      "  Downloading anthropic-0.34.2-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: pandas<2.3.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from inference) (2.2.3)\n",
      "Requirement already satisfied: pytest<9.0.0,>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from inference) (8.3.3)\n",
      "Requirement already satisfied: tokenizers<=0.20.3,>=0.19.0 in /opt/conda/lib/python3.10/site-packages (from inference) (0.20.3)\n",
      "Collecting slack-sdk~=3.33.4 (from inference)\n",
      "  Downloading slack_sdk-3.33.5-py2.py3-none-any.whl.metadata (15 kB)\n",
      "Collecting twilio~=9.3.7 (from inference)\n",
      "  Downloading twilio-9.3.8-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: httpx<0.28.0,>=0.25.1 in /opt/conda/lib/python3.10/site-packages (from inference) (0.27.0)\n",
      "Collecting onnxruntime<1.20.0,>=1.15.1 (from inference)\n",
      "  Downloading onnxruntime-1.19.2-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
      "Requirement already satisfied: nvidia-ml-py<13.0.0 in /opt/conda/lib/python3.10/site-packages (from inference) (11.495.46)\n",
      "Requirement already satisfied: docker<8.0.0,>=7.0.0 in /opt/conda/lib/python3.10/site-packages (from inference) (7.1.0)\n",
      "Requirement already satisfied: typer<=0.12.5,>=0.9.0 in /opt/conda/lib/python3.10/site-packages (from inference) (0.12.3)\n",
      "Requirement already satisfied: PyYAML~=6.0.0 in /opt/conda/lib/python3.10/site-packages (from inference) (6.0.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from inference) (4.66.4)\n",
      "Requirement already satisfied: py-cpuinfo~=9.0.0 in /opt/conda/lib/python3.10/site-packages (from inference) (9.0.0)\n",
      "Requirement already satisfied: aiohttp<=3.10.11,>=3.9.0 in /opt/conda/lib/python3.10/site-packages (from inference) (3.9.5)\n",
      "Collecting backoff~=2.2.0 (from inference)\n",
      "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting rich<13.10.0,>=13.0.0 (from inference)\n",
      "  Downloading rich-13.0.1-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: dataclasses-json~=0.6.0 in /opt/conda/lib/python3.10/site-packages (from inference) (0.6.7)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp<=3.10.11,>=3.9.0->inference) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<=3.10.11,>=3.9.0->inference) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp<=3.10.11,>=3.9.0->inference) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp<=3.10.11,>=3.9.0->inference) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<=3.10.11,>=3.9.0->inference) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<=3.10.11,>=3.9.0->inference) (4.0.3)\n",
      "Collecting aioice<1.0.0,>=0.9.0 (from aiortc<2.0.0,>=1.9.0->inference)\n",
      "  Downloading aioice-0.9.0-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting av<13.0.0,>=9.0.0 (from aiortc<2.0.0,>=1.9.0->inference)\n",
      "  Downloading av-12.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: cffi>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from aiortc<2.0.0,>=1.9.0->inference) (1.16.0)\n",
      "Requirement already satisfied: cryptography>=42.0.0 in /opt/conda/lib/python3.10/site-packages (from aiortc<2.0.0,>=1.9.0->inference) (42.0.8)\n",
      "Requirement already satisfied: google-crc32c>=1.1 in /opt/conda/lib/python3.10/site-packages (from aiortc<2.0.0,>=1.9.0->inference) (1.5.0)\n",
      "Collecting pyee>=9.0.0 (from aiortc<2.0.0,>=1.9.0->inference)\n",
      "  Downloading pyee-12.1.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting pylibsrtp>=0.10.0 (from aiortc<2.0.0,>=1.9.0->inference)\n",
      "  Downloading pylibsrtp-0.10.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: pyopenssl>=24.0.0 in /opt/conda/lib/python3.10/site-packages (from aiortc<2.0.0,>=1.9.0->inference) (24.0.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/conda/lib/python3.10/site-packages (from anthropic~=0.34.2->inference) (4.4.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/conda/lib/python3.10/site-packages (from anthropic~=0.34.2->inference) (1.9.0)\n",
      "Collecting jiter<1,>=0.4.0 (from anthropic~=0.34.2->inference)\n",
      "  Downloading jiter-0.8.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from anthropic~=0.34.2->inference) (1.3.1)\n",
      "Collecting tzlocal>=3.0 (from APScheduler<4.0.0,>=3.10.1->inference)\n",
      "  Downloading tzlocal-5.2-py3-none-any.whl.metadata (7.8 kB)\n",
      "Requirement already satisfied: aiofiles in /opt/conda/lib/python3.10/site-packages (from asyncua~=1.1.5->inference) (22.1.0)\n",
      "Requirement already satisfied: aiosqlite in /opt/conda/lib/python3.10/site-packages (from asyncua~=1.1.5->inference) (0.20.0)\n",
      "Requirement already satisfied: python-dateutil in /opt/conda/lib/python3.10/site-packages (from asyncua~=1.1.5->inference) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz in /opt/conda/lib/python3.10/site-packages (from asyncua~=1.1.5->inference) (2024.1)\n",
      "Collecting sortedcontainers (from asyncua~=1.1.5->inference)\n",
      "  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Collecting botocore<1.30.0,>=1.29.100 (from boto3<=1.35.60->inference)\n",
      "  Downloading botocore-1.29.165-py3-none-any.whl.metadata (5.9 kB)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from boto3<=1.35.60->inference) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from boto3<=1.35.60->inference) (0.6.2)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json~=0.6.0->inference) (3.23.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json~=0.6.0->inference) (0.9.0)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in /opt/conda/lib/python3.10/site-packages (from docker<8.0.0,>=7.0.0->inference) (1.26.18)\n",
      "Requirement already satisfied: starlette<0.38.0,>=0.37.2 in /opt/conda/lib/python3.10/site-packages (from fastapi<0.111,>=0.100->inference) (0.37.2)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from httpx<0.28.0,>=0.25.1->inference) (2024.6.2)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx<0.28.0,>=0.25.1->inference) (1.0.5)\n",
      "Requirement already satisfied: idna in /opt/conda/lib/python3.10/site-packages (from httpx<0.28.0,>=0.25.1->inference) (3.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx<0.28.0,>=0.25.1->inference) (0.14.0)\n",
      "Collecting coloredlogs (from onnxruntime<1.20.0,>=1.15.1->inference)\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: flatbuffers in /opt/conda/lib/python3.10/site-packages (from onnxruntime<1.20.0,>=1.15.1->inference) (24.3.25)\n",
      "Requirement already satisfied: protobuf in /opt/conda/lib/python3.10/site-packages (from onnxruntime<1.20.0,>=1.15.1->inference) (3.20.3)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from onnxruntime<1.20.0,>=1.15.1->inference) (1.13.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas<2.3.0,>=2.0.0->inference) (2024.1)\n",
      "Requirement already satisfied: prometheus-client<1.0.0,>=0.8.0 in /opt/conda/lib/python3.10/site-packages (from prometheus-fastapi-instrumentator<=6.0.0->inference) (0.20.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from pydantic~=2.6->inference) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in /opt/conda/lib/python3.10/site-packages (from pydantic~=2.6->inference) (2.27.1)\n",
      "Requirement already satisfied: pyparsing>=3 in /opt/conda/lib/python3.10/site-packages (from pydot~=2.0.0->inference) (3.1.2)\n",
      "Requirement already satisfied: iniconfig in /opt/conda/lib/python3.10/site-packages (from pytest<9.0.0,>=8.0.0->inference) (2.0.0)\n",
      "Requirement already satisfied: pluggy<2,>=1.5 in /opt/conda/lib/python3.10/site-packages (from pytest<9.0.0,>=8.0.0->inference) (1.5.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /opt/conda/lib/python3.10/site-packages (from pytest<9.0.0,>=8.0.0->inference) (1.2.0)\n",
      "Requirement already satisfied: tomli>=1 in /opt/conda/lib/python3.10/site-packages (from pytest<9.0.0,>=8.0.0->inference) (2.0.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.32.0->inference) (3.3.2)\n",
      "Collecting commonmark<0.10.0,>=0.9.0 (from rich<13.10.0,>=13.0.0->inference)\n",
      "  Downloading commonmark-0.9.1-py2.py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.6.0 in /opt/conda/lib/python3.10/site-packages (from rich<13.10.0,>=13.0.0->inference) (2.18.0)\n",
      "Requirement already satisfied: scipy>=1.9 in /opt/conda/lib/python3.10/site-packages (from scikit-image<=0.24.0,>=0.19.0->inference) (1.14.1)\n",
      "Requirement already satisfied: imageio>=2.33 in /opt/conda/lib/python3.10/site-packages (from scikit-image<=0.24.0,>=0.19.0->inference) (2.34.1)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in /opt/conda/lib/python3.10/site-packages (from scikit-image<=0.24.0,>=0.19.0->inference) (2024.5.22)\n",
      "Requirement already satisfied: lazy-loader>=0.4 in /opt/conda/lib/python3.10/site-packages (from scikit-image<=0.24.0,>=0.19.0->inference) (0.4)\n",
      "Requirement already satisfied: contourpy>=1.0.7 in /opt/conda/lib/python3.10/site-packages (from supervision<=0.30.0,>=0.25.1->inference) (1.2.1)\n",
      "Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from supervision<=0.30.0,>=0.25.1->inference) (0.7.1)\n",
      "Requirement already satisfied: matplotlib>=3.6.0 in /opt/conda/lib/python3.10/site-packages (from supervision<=0.30.0,>=0.25.1->inference) (3.7.5)\n",
      "Collecting requests-file>=1.4 (from tldextract~=5.1.2->inference)\n",
      "  Downloading requests_file-2.1.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: filelock>=3.0.8 in /opt/conda/lib/python3.10/site-packages (from tldextract~=5.1.2->inference) (3.15.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /opt/conda/lib/python3.10/site-packages (from tokenizers<=0.20.3,>=0.19.0->inference) (0.26.2)\n",
      "Requirement already satisfied: PyJWT<3.0.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from twilio~=9.3.7->inference) (2.8.0)\n",
      "Collecting aiohttp-retry==2.8.3 (from twilio~=9.3.7->inference)\n",
      "  Downloading aiohttp_retry-2.8.3-py3-none-any.whl.metadata (8.9 kB)\n",
      "Requirement already satisfied: click>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from typer<=0.12.5,>=0.9.0->inference) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /opt/conda/lib/python3.10/site-packages (from typer<=0.12.5,>=0.9.0->inference) (1.5.4)\n",
      "Requirement already satisfied: dnspython>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from aioice<1.0.0,>=0.9.0->aiortc<2.0.0,>=1.9.0->inference) (2.6.1)\n",
      "Collecting ifaddr>=0.2.0 (from aioice<1.0.0,>=0.9.0->aiortc<2.0.0,>=1.9.0->inference)\n",
      "  Downloading ifaddr-0.2.0-py3-none-any.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.10/site-packages (from cffi>=1.0.0->aiortc<2.0.0,>=1.9.0->inference) (2.22)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<=0.20.3,>=0.19.0->inference) (2024.9.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.6.0->supervision<=0.30.0,>=0.25.1->inference) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.6.0->supervision<=0.30.0,>=0.25.1->inference) (4.53.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.6.0->supervision<=0.30.0,>=0.25.1->inference) (1.4.5)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil->asyncua~=1.1.5->inference) (1.16.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json~=0.6.0->inference) (1.0.0)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime<1.20.0,>=1.15.1->inference)\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->onnxruntime<1.20.0,>=1.15.1->inference) (1.3.0)\n",
      "Downloading inference-0.31.1-py3-none-any.whl (888 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m888.6/888.6 kB\u001b[0m \u001b[31m29.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading aiortc-1.9.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m50.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading anthropic-0.34.2-py3-none-any.whl (891 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m891.9/891.9 kB\u001b[0m \u001b[31m33.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading APScheduler-3.11.0-py3-none-any.whl (64 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.0/64.0 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading asyncua-1.1.5-py3-none-any.whl (774 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m774.7/774.7 kB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Downloading fastapi-0.110.3-py3-none-any.whl (91 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.8/91.8 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading onnxruntime-1.19.2-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (13.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.2/13.2 MB\u001b[0m \u001b[31m53.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading openai-1.57.4-py3-none-any.whl (390 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m390.3/390.3 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading packaging-24.2-py3-none-any.whl (65 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading prometheus_fastapi_instrumentator-6.0.0-py3-none-any.whl (18 kB)\n",
      "Downloading pydantic_settings-2.7.0-py3-none-any.whl (29 kB)\n",
      "Downloading pydot-2.0.0-py3-none-any.whl (22 kB)\n",
      "Downloading redis-5.0.8-py3-none-any.whl (255 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m255.6/255.6 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading rich-13.0.1-py3-none-any.whl (238 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m238.1/238.1 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading shapely-2.0.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m57.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading slack_sdk-3.33.5-py2.py3-none-any.whl (292 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m292.3/292.3 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading structlog-24.4.0-py3-none-any.whl (67 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.2/67.2 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading supervision-0.25.1-py3-none-any.whl (181 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.5/181.5 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tldextract-5.1.3-py3-none-any.whl (104 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.9/104.9 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading twilio-9.3.8-py2.py3-none-any.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m46.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading aiohttp_retry-2.8.3-py3-none-any.whl (9.8 kB)\n",
      "Downloading zxing_cpp-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (940 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m940.0/940.0 kB\u001b[0m \u001b[31m34.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading aioice-0.9.0-py3-none-any.whl (24 kB)\n",
      "Downloading av-12.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (33.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33.5/33.5 MB\u001b[0m \u001b[31m45.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading botocore-1.29.165-py3-none-any.whl (11.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.0/11.0 MB\u001b[0m \u001b[31m80.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading commonmark-0.9.1-py2.py3-none-any.whl (51 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.1/51.1 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jiter-0.8.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (345 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m345.0/345.0 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyee-12.1.1-py3-none-any.whl (15 kB)\n",
      "Downloading pylibsrtp-0.10.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m58.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading requests_file-2.1.0-py2.py3-none-any.whl (4.2 kB)\n",
      "Downloading tzlocal-5.2-py3-none-any.whl (17 kB)\n",
      "Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
      "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ifaddr-0.2.0-py3-none-any.whl (12 kB)\n",
      "Building wheels for collected packages: pybase64\n",
      "  Building wheel for pybase64 (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pybase64: filename=pybase64-1.0.2-cp310-cp310-linux_x86_64.whl size=39875 sha256=d2a3b3ba845280d1804f9a1a5a247254eed036d75943bfafd25ac55b35bdc1f2\n",
      "  Stored in directory: /root/.cache/pip/wheels/e8/ab/d3/ad772f5bdac5c921effc923ba9260e78a9b0858904790dfa08\n",
      "Successfully built pybase64\n",
      "Installing collected packages: sortedcontainers, ifaddr, commonmark, zxing-cpp, tzlocal, structlog, slack-sdk, shapely, rich, redis, pyee, pydot, pybase64, packaging, jiter, humanfriendly, backoff, av, aioice, requests-toolbelt, requests-file, pylibsrtp, coloredlogs, botocore, APScheduler, tldextract, supervision, pydantic-settings, openai, onnxruntime, fastapi, aiohttp-retry, twilio, prometheus-fastapi-instrumentator, asyncua, anthropic, aiortc, inference\n",
      "  Attempting uninstall: shapely\n",
      "    Found existing installation: Shapely 1.8.5.post1\n",
      "    Uninstalling Shapely-1.8.5.post1:\n",
      "      Successfully uninstalled Shapely-1.8.5.post1\n",
      "  Attempting uninstall: rich\n",
      "    Found existing installation: rich 13.7.1\n",
      "    Uninstalling rich-13.7.1:\n",
      "      Successfully uninstalled rich-13.7.1\n",
      "  Attempting uninstall: pydot\n",
      "    Found existing installation: pydot 1.4.2\n",
      "    Uninstalling pydot-1.4.2:\n",
      "      Successfully uninstalled pydot-1.4.2\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 21.3\n",
      "    Uninstalling packaging-21.3:\n",
      "      Successfully uninstalled packaging-21.3\n",
      "  Attempting uninstall: requests-toolbelt\n",
      "    Found existing installation: requests-toolbelt 0.10.1\n",
      "    Uninstalling requests-toolbelt-0.10.1:\n",
      "      Successfully uninstalled requests-toolbelt-0.10.1\n",
      "  Attempting uninstall: botocore\n",
      "    Found existing installation: botocore 1.35.36\n",
      "    Uninstalling botocore-1.35.36:\n",
      "      Successfully uninstalled botocore-1.35.36\n",
      "  Attempting uninstall: fastapi\n",
      "    Found existing installation: fastapi 0.111.0\n",
      "    Uninstalling fastapi-0.111.0:\n",
      "      Successfully uninstalled fastapi-0.111.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "aiobotocore 2.15.2 requires botocore<1.35.37,>=1.35.16, but you have botocore 1.29.165 which is incompatible.\n",
      "apache-beam 2.46.0 requires cloudpickle~=2.2.1, but you have cloudpickle 3.1.0 which is incompatible.\n",
      "apache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.8 which is incompatible.\n",
      "apache-beam 2.46.0 requires numpy<1.25.0,>=1.14.3, but you have numpy 1.26.4 which is incompatible.\n",
      "apache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 18.1.0 which is incompatible.\n",
      "apache-beam 2.46.0 requires pydot<2,>=1.2.0, but you have pydot 2.0.0 which is incompatible.\n",
      "google-cloud-bigquery 2.34.4 requires packaging<22.0dev,>=14.3, but you have packaging 24.2 which is incompatible.\n",
      "ibis-framework 7.1.0 requires pyarrow<15,>=2, but you have pyarrow 18.1.0 which is incompatible.\n",
      "jupyterlab 4.3.1 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\n",
      "jupyterlab-lsp 5.1.0 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\n",
      "kfp 2.5.0 requires google-cloud-storage<3,>=2.2.1, but you have google-cloud-storage 1.44.0 which is incompatible.\n",
      "kfp 2.5.0 requires requests-toolbelt<1,>=0.8.0, but you have requests-toolbelt 1.0.0 which is incompatible.\n",
      "mlxtend 0.23.3 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\n",
      "plotnine 0.14.3 requires matplotlib>=3.8.0, but you have matplotlib 3.7.5 which is incompatible.\n",
      "tensorflow 2.16.1 requires ml-dtypes~=0.3.1, but you have ml-dtypes 0.5.0 which is incompatible.\n",
      "tensorflow-transform 0.14.0 requires pydot<2,>=1.2.0, but you have pydot 2.0.0 which is incompatible.\n",
      "textual 0.67.1 requires rich>=13.3.3, but you have rich 13.0.1 which is incompatible.\n",
      "thinc 8.3.2 requires numpy<2.1.0,>=2.0.0; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
      "ydata-profiling 4.12.0 requires scipy<1.14,>=1.4.1, but you have scipy 1.14.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed APScheduler-3.11.0 aiohttp-retry-2.8.3 aioice-0.9.0 aiortc-1.9.0 anthropic-0.34.2 asyncua-1.1.5 av-12.3.0 backoff-2.2.1 botocore-1.29.165 coloredlogs-15.0.1 commonmark-0.9.1 fastapi-0.110.3 humanfriendly-10.0 ifaddr-0.2.0 inference-0.31.1 jiter-0.8.2 onnxruntime-1.19.2 openai-1.57.4 packaging-24.2 prometheus-fastapi-instrumentator-6.0.0 pybase64-1.0.2 pydantic-settings-2.7.0 pydot-2.0.0 pyee-12.1.1 pylibsrtp-0.10.0 redis-5.0.8 requests-file-2.1.0 requests-toolbelt-1.0.0 rich-13.0.1 shapely-2.0.6 slack-sdk-3.33.5 sortedcontainers-2.4.0 structlog-24.4.0 supervision-0.25.1 tldextract-5.1.3 twilio-9.3.8 tzlocal-5.2 zxing-cpp-2.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T16:10:42.647094Z",
     "iopub.status.busy": "2024-12-12T16:10:42.646769Z",
     "iopub.status.idle": "2024-12-12T16:10:53.919641Z",
     "shell.execute_reply": "2024-12-12T16:10:53.918586Z",
     "shell.execute_reply.started": "2024-12-12T16:10:42.647062Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "pip install mediapipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T16:10:53.921901Z",
     "iopub.status.busy": "2024-12-12T16:10:53.921229Z",
     "iopub.status.idle": "2024-12-12T16:11:13.764295Z",
     "shell.execute_reply": "2024-12-12T16:11:13.763312Z",
     "shell.execute_reply.started": "2024-12-12T16:10:53.921855Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from inference import get_model\n",
    "import supervision as sv\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "# import preprocessing as prep\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "# from sklearn.neighbors import NearestNeighbors\n",
    "# import imutils\n",
    "# import math\n",
    "# from sklearn.cluster import DBSCAN\n",
    "# from skimage.morphology import skeletonize\n",
    "import time\n",
    "# from ultralytics import YOLO\n",
    "# from ultralytics.utils.plotting import Annotator\n",
    "import scipy.spatial as spatial\n",
    "from statistics import mean\n",
    "import scipy.cluster as cluster\n",
    "# from inference import get_model\n",
    "from PIL import Image, ImageChops\n",
    "# from imutils.object_detection import non_max_suppression\n",
    "# import pytesseract\n",
    "# pytesseract.pytesseract.tesseract_cmd = r'C:\\\\Program Files\\\\Tesseract-OCR\\\\tesseract.exe'\n",
    "import torch\n",
    "# import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch import nn, optim\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "# import eminst\n",
    "# import tensorflow as tf\n",
    "import mediapipe as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T16:11:13.766650Z",
     "iopub.status.busy": "2024-12-12T16:11:13.766080Z",
     "iopub.status.idle": "2024-12-12T16:11:13.777841Z",
     "shell.execute_reply": "2024-12-12T16:11:13.777043Z",
     "shell.execute_reply.started": "2024-12-12T16:11:13.766620Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T16:11:13.779914Z",
     "iopub.status.busy": "2024-12-12T16:11:13.779331Z",
     "iopub.status.idle": "2024-12-12T16:11:13.799613Z",
     "shell.execute_reply": "2024-12-12T16:11:13.798606Z",
     "shell.execute_reply.started": "2024-12-12T16:11:13.779860Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def augment_points(points):\n",
    "    points_shape = list(np.shape(points))\n",
    "    augmented_points = []\n",
    "    for row in range(int(points_shape[0] / 11)):\n",
    "        start = row * 11\n",
    "        end = (row * 11) + 10\n",
    "        rw_points = points[start:end + 1]\n",
    "        rw_y = []\n",
    "        rw_x = []\n",
    "        for point in rw_points:\n",
    "            x, y = point\n",
    "            rw_y.append(y)\n",
    "            rw_x.append(x)\n",
    "        y_mean = mean(rw_y)\n",
    "        for i in range(len(rw_x)):\n",
    "            point = (rw_x[i], y_mean)\n",
    "            augmented_points.append(point)\n",
    "    augmented_points = sorted(augmented_points, key=lambda k: [k[1], k[0]])\n",
    "    return augmented_points\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T16:11:13.801388Z",
     "iopub.status.busy": "2024-12-12T16:11:13.801021Z",
     "iopub.status.idle": "2024-12-12T16:11:13.812059Z",
     "shell.execute_reply": "2024-12-12T16:11:13.811094Z",
     "shell.execute_reply.started": "2024-12-12T16:11:13.801346Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def intersection_of_line(line1, line2):\n",
    "    rho1, theta1 = line1\n",
    "    rho2, theta2 = line2\n",
    "    A = np.array([\n",
    "        [np.cos(theta1), np.sin(theta1)],\n",
    "        [np.cos(theta2), np.sin(theta2)]\n",
    "    ])\n",
    "    b = np.array([[rho1], [rho2]])\n",
    "    x0, y0 = np.linalg.solve(A, b)\n",
    "    x0, y0 = int(np.round(x0)), int(np.round(y0))\n",
    "    return [x0, y0]\n",
    "\n",
    "\n",
    "def find_intersections_point(vertical_lines, horizontal_lines):\n",
    "    intersections = []\n",
    "    for v_line in vertical_lines:\n",
    "        for h_line in horizontal_lines:\n",
    "            intersections.append(intersection_of_line(v_line, h_line))\n",
    "    return intersections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T16:11:13.814501Z",
     "iopub.status.busy": "2024-12-12T16:11:13.814110Z",
     "iopub.status.idle": "2024-12-12T16:11:13.911971Z",
     "shell.execute_reply": "2024-12-12T16:11:13.911207Z",
     "shell.execute_reply.started": "2024-12-12T16:11:13.814459Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_board_mask(image, model, threshold=0, expansion_factor=0):\n",
    "    # Create an empty mask of the same size as the input image\n",
    "    mask = np.zeros_like(image, dtype=np.uint8)\n",
    "    \n",
    "    # Get the results from the model\n",
    "    results = model(image)\n",
    "    \n",
    "    # Initialize edge variable\n",
    "    edge = None\n",
    "    \n",
    "    for result in results:\n",
    "        for box in result.boxes:\n",
    "            # Extract bounding box coordinates\n",
    "            x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "            x1 = max(0, x1)\n",
    "            y1 = max(0, y1)\n",
    "            x2 = min(image.shape[1], x2)\n",
    "            y2 = min(image.shape[0], y2)\n",
    "            \n",
    "            # Compute the length of the bounding box diagonal (edge length)\n",
    "            edge_length = np.linalg.norm(np.array([x2 - x1, y2 - y1]))  \n",
    "            \n",
    "            # If the edge length is above the threshold, process it\n",
    "            if edge_length >= threshold:\n",
    "                # Expand the bounding box based on the threshold\n",
    "                x1_expanded = max(0, x1 - expansion_factor)\n",
    "                y1_expanded = max(0, y1 - expansion_factor)\n",
    "                x2_expanded = min(image.shape[1], x2 + expansion_factor)\n",
    "                y2_expanded = min(image.shape[0], y2 + expansion_factor)\n",
    "\n",
    "                # Create the expanded bounding box points\n",
    "                top_left = (x1_expanded, y1_expanded)\n",
    "                bottom_right = (x2_expanded, y2_expanded)\n",
    "                top_right = (x2_expanded, y1_expanded)\n",
    "                bottom_left = (x1_expanded, y2_expanded)\n",
    "\n",
    "                # Define the expanded polygon and fill the mask\n",
    "                points = np.array([[top_left, top_right, bottom_right, bottom_left]], dtype=np.int32)\n",
    "                cv2.fillPoly(mask, points, (255, 255, 255))\n",
    "                \n",
    "                # Store the edge (expanded bounding box coordinates) for return\n",
    "                edge = np.array([[x1_expanded, y1_expanded], [x2_expanded, y1_expanded], \n",
    "                                 [x1_expanded, y2_expanded], [x2_expanded, y2_expanded]], dtype=np.float32)\n",
    "    return mask, edge\n",
    "\n",
    "def categorize_hough_lines(lines, angle_threshold=np.radians(10)):\n",
    "        vertical_lines = []\n",
    "        horizontal_lines = []\n",
    "        for rho, theta in lines:\n",
    "            theta = theta % np.pi\n",
    "            if abs(theta - np.pi/2) < angle_threshold:\n",
    "                vertical_lines.append((rho, theta))\n",
    "            elif theta < angle_threshold or abs(theta - np.pi) < angle_threshold:\n",
    "                horizontal_lines.append((rho, theta))\n",
    "        return vertical_lines, horizontal_lines\n",
    "\n",
    "def cluster_intersections(points, threshold):\n",
    "    clusters = []\n",
    "    visited = [False] * len(points)  \n",
    "    for i, point1 in enumerate(points):\n",
    "        if visited[i]:\n",
    "            continue\n",
    "        cluster = [point1]\n",
    "        visited[i] = True\n",
    "        for j, point2 in enumerate(points):\n",
    "            if not visited[j] and euclidean_distance(point1, point2) < threshold:\n",
    "                cluster.append(point2)\n",
    "                visited[j] = True\n",
    "        centroid_x = np.mean([p[0] for p in cluster])\n",
    "        centroid_y = np.mean([p[1] for p in cluster])\n",
    "        clusters.append((centroid_x, centroid_y))  \n",
    "    return clusters\n",
    "def euclidean_distance(p1, p2):\n",
    "    return np.sqrt((p1[0] - p2[0])**2 + (p1[1] - p2[1])**2)\n",
    "\n",
    "\n",
    "def crop_board(image,mask):\n",
    "    return cv2.bitwise_and(image,mask)\n",
    "\n",
    "def get_grid(image):\n",
    "    \n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)  \n",
    "    gray = cv2.GaussianBlur(gray,(5,5),0)\n",
    "    edges = cv2.Canny(gray, 30, 100)\n",
    "    \n",
    "    height, width = image.shape[:2]\n",
    "\n",
    "    grid = [[[] for _ in range(8)] for _ in range(8)]\n",
    "\n",
    "    grid_visualization = np.zeros_like(gray)\n",
    "    \n",
    "    image = cv2.bitwise_not(grid_visualization)\n",
    "    edge_width = int(0.01 * min(height, width))\n",
    "    mask = np.zeros((height, width), dtype=np.uint8)\n",
    "    top = edge_width\n",
    "    left = edge_width\n",
    "    bottom = height - edge_width\n",
    "    right = width - edge_width\n",
    "\n",
    "    mask[top:bottom, left:right] = 1\n",
    "\n",
    "    edges = cv2.bitwise_and(edges,mask)\n",
    "    \n",
    "    \n",
    "    lines = cv2.HoughLines(edges, 1, np.pi / 180, 130)\n",
    "\n",
    "    \n",
    "    if lines is not None:\n",
    "        for line in lines:\n",
    "            rho, theta = line[0]\n",
    "            epsilon = 0.1  \n",
    "            if abs(theta) < epsilon or abs(theta - np.pi) < epsilon or abs(theta - np.pi / 2) < epsilon:\n",
    "                x1 = int(rho * np.cos(theta) + 1000 * (-np.sin(theta)))\n",
    "                y1 = int(rho * np.sin(theta) + 1000 * (np.cos(theta)))\n",
    "                x2 = int(rho * np.cos(theta) - 1000 * (-np.sin(theta)))\n",
    "                y2 = int(rho * np.sin(theta) - 1000 * (np.cos(theta)))\n",
    "                cv2.line(grid_visualization, (x1, y1), (x2, y2), 255,2)\n",
    "    \n",
    "    grid_visualization = cv2.bitwise_not(grid_visualization)\n",
    "\n",
    "    # Find connected components\n",
    "    num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(grid_visualization, connectivity=8)\n",
    "    \n",
    "    # Filter and process centroids\n",
    "    centroid_list = [\n",
    "        (centroids[i][0], centroids[i][1], i, stats[i, cv2.CC_STAT_WIDTH], stats[i, cv2.CC_STAT_HEIGHT]) \n",
    "        for i in range(1, num_labels) \n",
    "        if stats[i, cv2.CC_STAT_AREA] > 2500 \n",
    "    ]  \n",
    "    \n",
    "\n",
    "    if(len(centroid_list) !=  64): \n",
    "        print(\"Invalid Grid Initialization\")\n",
    "        return False,grid\n",
    "    \n",
    "    # Sort centroids\n",
    "    centroid_list.sort(key=lambda x: x[1])  \n",
    "    \n",
    "    # Organize centroids into rows\n",
    "    rows = [[] for _ in range(8)]\n",
    "    for i, (cx, cy, label, width, height) in enumerate(centroid_list):\n",
    "        row = i // 8  \n",
    "        if len(rows) <= row:\n",
    "            rows.extend([[] for _ in range(row - len(rows) + 1)])  \n",
    "        rows[row].append((cx, cy, i + 1, label, width, height))\n",
    "            \n",
    "    # Sort each row by x-coordinate\n",
    "    for row in rows:\n",
    "        row.sort(key=lambda x: x[0])  \n",
    "    \n",
    "    # Process grid with dimensional information\n",
    "    for i, row in enumerate(rows):\n",
    "        for j, (cx, cy, idx, label, width, height) in enumerate(row):\n",
    "            # Calculate width and height based on neighbors\n",
    "            right_neighbor = row[j + 1] if j + 1 < len(row) else None\n",
    "            below_neighbor = rows[i + 1][j] if i + 1 < len(rows) and j < len(rows[i + 1]) else None\n",
    "            \n",
    "            computed_width = (right_neighbor[0] - cx) if right_neighbor else width\n",
    "            computed_height = (below_neighbor[1] - cy) if below_neighbor else height\n",
    "            \n",
    "            # Update grid matrix with (x, y, width, height)\n",
    "            if i < 8 and j < 8:\n",
    "                grid[i][j] = {\n",
    "                    'x': cx,\n",
    "                    'y': cy,\n",
    "                    'width': computed_width,\n",
    "                    'height': computed_height\n",
    "                }\n",
    "                \n",
    "    return True,grid\n",
    "    \n",
    "\n",
    "    \n",
    "def get_board_coordination(grid):\n",
    "    coordinate = []\n",
    "    return coordinate\n",
    "\n",
    "    \n",
    "\n",
    "def get_board_corner(image, model=None, distance_threshold=30):\n",
    "\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    kernel1 = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (11,11))\n",
    "    close = cv2.morphologyEx(gray, cv2.MORPH_CLOSE, kernel1)\n",
    "    \n",
    "    blurred = cv2.GaussianBlur(close, (3, 3), 0)\n",
    "    edges = cv2.Canny(blurred, 50, 150)\n",
    "   \n",
    "    lines = cv2.HoughLines(edges, 1, np.pi / 180, threshold=100)\n",
    "    \n",
    "    horizontal_lines = []\n",
    "    vertical_lines = []\n",
    "    \n",
    "    if lines is not None:\n",
    "        for line in lines:\n",
    "            rho, theta = line[0]\n",
    "            \n",
    "            a = np.cos(theta)\n",
    "            b = np.sin(theta)\n",
    "            x0 = a * rho\n",
    "            y0 = b * rho\n",
    "            \n",
    "            x1 = int(x0 + 1000 * (-b))\n",
    "            y1 = int(y0 + 1000 * (a))\n",
    "            x2 = int(x0 - 1000 * (-b))\n",
    "            y2 = int(y0 - 1000 * (a))\n",
    "            \n",
    "            if (theta < np.pi / 4 or theta > 3 * np.pi / 4): \n",
    "                vertical_lines.append((rho, theta))\n",
    "            else:  \n",
    "                horizontal_lines.append((rho, theta))\n",
    "    \n",
    "    \n",
    "    intersections_points = find_intersections_point(vertical_lines, horizontal_lines)\n",
    "    \n",
    "    if not intersections_points or len(intersections_points) < 4:\n",
    "        raise ValueError(\"Not enough intersection points found to determine grid corners\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    top_left = min(intersections_points, key=lambda p: p[0] + p[1])\n",
    "    \n",
    "    top_right = max(intersections_points, key=lambda p: p[0] - p[1])\n",
    "    \n",
    "    bottom_left = max(intersections_points, key=lambda p: p[1] - p[0])\n",
    "    \n",
    "    bottom_right = max(intersections_points, key=lambda p: p[0] + p[1])\n",
    "    \n",
    "    corners = [(top_left), (top_right), (bottom_right),(bottom_left)]\n",
    "    corners = np.array(corners, dtype=np.float32)\n",
    "    \n",
    "    return  corners\n",
    "\n",
    "\n",
    "\n",
    "def polygon_area(points):\n",
    "    points = np.array(points)\n",
    "    x = points[:, 0]\n",
    "    y = points[:, 1]\n",
    "    area = 0.5 * np.abs(np.dot(x, np.roll(y, 1)) - np.dot(y, np.roll(x, 1)))\n",
    "    return area\n",
    "\n",
    "def find_rectangle_by_point(points, num_points=4):\n",
    "    rectangles = []\n",
    "    for i, point in enumerate(points):\n",
    "        x, y = point\n",
    "        distances = [] \n",
    "        for j, other_point in enumerate(points):\n",
    "            if i != j: \n",
    "                dist = euclidean_distance(point, other_point)\n",
    "                distances.append((dist, other_point))\n",
    "        distances.sort(key=lambda x: x[0]) \n",
    "        closest_points = [p for _, p in distances[:num_points]]  \n",
    "        rectangle = [point] + closest_points\n",
    "        rectangles.append(rectangle)\n",
    "    return rectangles\n",
    "\n",
    "\n",
    "\n",
    "def calculate_centroids(clusters):\n",
    "    centroids = []\n",
    "    for cluster in clusters:\n",
    "        cluster_array = np.array(cluster)  \n",
    "        centroid = cluster_array.mean(axis=0) \n",
    "        centroids.append(centroid.tolist())\n",
    "    return centroids\n",
    "\n",
    "\n",
    "def h_v_lines(lines):\n",
    "    h_lines, v_lines = [], []\n",
    "    for rho, theta in lines[:,0]:\n",
    "        if theta < np.pi / 4 or theta > np.pi - np.pi / 4:\n",
    "            v_lines.append([rho, theta])\n",
    "        else:\n",
    "            h_lines.append([rho, theta])\n",
    "    return h_lines, v_lines\n",
    "\n",
    "def line_intersections(h_lines, v_lines):\n",
    "    points = []\n",
    "    for r_h, t_h in h_lines:\n",
    "        for r_v, t_v in v_lines:\n",
    "            a = np.array([[np.cos(t_h), np.sin(t_h)], [np.cos(t_v), np.sin(t_v)]])\n",
    "            b = np.array([r_h, r_v])\n",
    "            inter_point = np.linalg.solve(a, b)\n",
    "            points.append(inter_point)\n",
    "    return np.array(points)\n",
    "\n",
    "def calculate_cluster_points(points):\n",
    "    dists = spatial.distance.pdist(points)\n",
    "    single_linkage = cluster.hierarchy.single(dists)\n",
    "    flat_clusters = cluster.hierarchy.fcluster(single_linkage, 15, 'distance')\n",
    "    cluster_dict = defaultdict(list)\n",
    "    for i in range(len(flat_clusters)):\n",
    "        cluster_dict[flat_clusters[i]].append(points[i])\n",
    "    cluster_values = cluster_dict.values()\n",
    "    clusters = map(lambda arr: (np.mean(np.array(arr)[:, 0]), np.mean(np.array(arr)[:, 1])), cluster_values)\n",
    "    return sorted(list(clusters), key=lambda k: [k[1], k[0]])\n",
    "    \n",
    "\n",
    "def adjust_gamma(image, gamma=1.0):\n",
    "    inv_gamma = 1.0 / gamma\n",
    "    table = np.array([((i / 255.0) ** inv_gamma) * 255 for i in range(256)]).astype(\"uint8\")\n",
    "    return cv2.LUT(image, table)\n",
    "\n",
    "def get_board_line(image, vertical_length=20, horizontal_length=20):\n",
    "    canny = cv2.Canny(image,50,150)\n",
    "    lines = cv2.HoughLines(canny, 1, np.pi / 180, 200) \n",
    "    if lines is not None:\n",
    "        for rho, theta in lines[:, 0]:\n",
    "            a = np.cos(theta)\n",
    "            b = np.sin(theta)\n",
    "            x0 = a * rho\n",
    "            y0 = b * rho\n",
    "            x1 = int(x0 + 1000 * (-b))\n",
    "            y1 = int(y0 + 1000 * a)\n",
    "            x2 = int(x0 - 1000 * (-b))\n",
    "            y2 = int(y0 - 1000 * a)\n",
    "            cv2.line(image, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "    return image\n",
    "\n",
    "def test_board(image, model):\n",
    "    results = model(image,conf=0.1)\n",
    "    annotated_image = results[0].plot()\n",
    "    return annotated_image\n",
    "\n",
    "def trim(image):\n",
    "    im = Image.fromarray(image)\n",
    "    bg = Image.new(im.mode, im.size, im.getpixel((0,0)))\n",
    "    diff = ImageChops.difference(im, bg)\n",
    "    diff = ImageChops.add(diff, diff, 2.0, -100)\n",
    "    bbox = diff.getbbox()\n",
    "    if bbox:\n",
    "        return np.asarray(im.crop(bbox))    \n",
    "    return im\n",
    "    \n",
    "def apply_perspective_transform(image,original_point):\n",
    "    destination = np.float32([[0, 0], [640, 0], [640, 640], [0, 640]])\n",
    "    matrix = cv2.getPerspectiveTransform(original_point, destination)\n",
    "    warp = cv2.warpPerspective(image, matrix, (640, 640))\n",
    "    return warp,matrix\n",
    "\n",
    "def call_pretrain(image, model):\n",
    "    results = model.infer(image)[0] \n",
    "    predictions = results.predictions\n",
    "    bounding_boxes = [] \n",
    "    for pred in predictions:\n",
    "        x = int(pred.x)\n",
    "        y = int(pred.y)\n",
    "        width = int(pred.width)\n",
    "        height = int(pred.height)\n",
    "        confident = pred.confidence\n",
    "        class_name = pred.class_name\n",
    "        bbox_dict = {\n",
    "            'class_name': class_name,\n",
    "            'x': x,\n",
    "            'y': y,\n",
    "            'width': width,\n",
    "            'height': height,\n",
    "            'confidence': confident,\n",
    "        }\n",
    "        bounding_boxes.append(bbox_dict)\n",
    "    \n",
    "    return bounding_boxes\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def sharpen_image(image):\n",
    "    kernel = np.array([[0, -1, 0],\n",
    "                       [-1, 5, -1],\n",
    "                       [0, -1, 0]])\n",
    "    sharpened_image = cv2.filter2D(image, -1, kernel)\n",
    "    return sharpened_image\n",
    "\n",
    "def get_chess_prediction(image,model):\n",
    "    results = call_pretrain(image,model)\n",
    "    return results\n",
    "    \n",
    "def get_annotated_image(image, bounding_boxes):\n",
    "    annotated_image = image.copy()\n",
    "    \n",
    "    for bbox in bounding_boxes:\n",
    "        x = bbox['x']\n",
    "        y = bbox['y']\n",
    "        width = bbox['width']\n",
    "        height = bbox['height']\n",
    "        confidence = bbox['confidence']\n",
    "        class_name = bbox['class_name']\n",
    "        x1 = int(x - width // 2)\n",
    "        y1 = int(y - height // 2)\n",
    "        x2 = int(x + width // 2)\n",
    "        y2 = int(y + height // 2)\n",
    "        cv2.rectangle(annotated_image, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "        text = f\"{class_name}: {confidence:.2f}\"\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        font_scale = 0.4\n",
    "        font_thickness = 1\n",
    "        text_size = cv2.getTextSize(text, font, font_scale, font_thickness)[0]\n",
    "        text_x = x1\n",
    "        text_y = y1 - 10\n",
    "        if text_y < 0:\n",
    "            text_y = y1 + 10\n",
    "        cv2.rectangle(annotated_image, \n",
    "                      (text_x, text_y - text_size[1] - 5), \n",
    "                      (text_x + text_size[0], text_y), \n",
    "                      (0, 255, 0), \n",
    "                      -1)\n",
    "        cv2.putText(annotated_image, text, (text_x, text_y), \n",
    "                    font, font_scale, (0, 0, 0), font_thickness)\n",
    "    return annotated_image\n",
    "\n",
    "def transform_to_original_grid(perspective_grid, M_inv):\n",
    "    # Create a new list to store the transformed grid\n",
    "    transformed_grid = [[None for _ in range(len(perspective_grid[0]))] for _ in range(len(perspective_grid))]\n",
    "    \n",
    "    for i in range(len(perspective_grid)):\n",
    "        for j in range(len(perspective_grid[i])):\n",
    "            if perspective_grid[i][j] is not None:\n",
    "                cell = perspective_grid[i][j]\n",
    "                # print(f\"Cell at [{i}][{j}]: {cell}\")  # Detailed print to check the structure\n",
    "                if isinstance(cell, dict):  # Ensure that the cell is a dictionary\n",
    "                    x, y, width, height = cell['x'], cell['y'], cell['width'], cell['height']\n",
    "                    pt1 = np.array([x, y, 1]).reshape(3, 1) \n",
    "                    transformed_pt1 = np.dot(M_inv, pt1)\n",
    "                    transformed_pt1 /= transformed_pt1[2]  \n",
    "                    transformed_x, transformed_y = transformed_pt1[0], transformed_pt1[1]\n",
    "                    pt2 = np.array([x + width, y + height, 1]).reshape(3, 1)\n",
    "                    transformed_pt2 = np.dot(M_inv, pt2)\n",
    "                    transformed_pt2 /= transformed_pt2[2]\n",
    "                    transformed_x2, transformed_y2 = transformed_pt2[0], transformed_pt2[1]\n",
    "                    transformed_width = transformed_x2 - transformed_x\n",
    "                    transformed_height = transformed_y2 - transformed_y\n",
    "                    transformed_grid[i][j] = {\n",
    "                        'x': transformed_x,\n",
    "                        'y': transformed_y,\n",
    "                        'width': transformed_width,\n",
    "                        'height': transformed_height\n",
    "                    }\n",
    "                    \n",
    "    return transformed_grid\n",
    "\n",
    "\n",
    "def transform_prediction_to_perspective(predictions, perspective_matrix):\n",
    "    transformed_predictions = []\n",
    "\n",
    "    for prediction in predictions:\n",
    "        class_name = prediction['class_name']\n",
    "        x, y = prediction['x'], prediction['y']\n",
    "        width, height = prediction['width'], prediction['height']\n",
    "        confidence = prediction['confidence']\n",
    "        \n",
    "        x1, y1 = x - width / 2, y - height / 2\n",
    "        x2, y2 = x + width / 2, y + height / 2\n",
    "\n",
    "        pt1 = np.array([x1, y1, 1]).reshape(3, 1)\n",
    "        pt2 = np.array([x2, y2, 1]).reshape(3, 1)\n",
    "\n",
    "        transformed_pt1 = np.dot(perspective_matrix, pt1)\n",
    "        transformed_pt2 = np.dot(perspective_matrix, pt2)\n",
    "\n",
    "        transformed_pt1 /= transformed_pt1[2]\n",
    "        transformed_pt2 /= transformed_pt2[2]\n",
    "\n",
    "        transformed_x1, transformed_y1 = transformed_pt1[0], transformed_pt1[1]\n",
    "        transformed_x2, transformed_y2 = transformed_pt2[0], transformed_pt2[1]\n",
    "\n",
    "        transformed_width = transformed_x2 - transformed_x1\n",
    "        transformed_height = transformed_y2 - transformed_y1\n",
    "\n",
    "        transformed_x = transformed_x1 + transformed_width / 2\n",
    "        transformed_y = transformed_y1 + transformed_height / 2\n",
    "\n",
    "        transformed_prediction = {\n",
    "            'class_name': class_name,\n",
    "            'x': transformed_x,\n",
    "            'y': transformed_y,\n",
    "            'width': transformed_width,\n",
    "            'height': transformed_height,\n",
    "            'confidence': confidence\n",
    "        }\n",
    "\n",
    "        transformed_predictions.append(transformed_prediction)\n",
    "\n",
    "    return transformed_predictions    \n",
    "\n",
    "\n",
    "        \n",
    "            \n",
    "            \n",
    "def remove_objects_and_crop(image, min_area=1000):\n",
    "    image_area = image.shape[0] * image.shape[1]\n",
    "    contours, _ = cv2.findContours(image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    mask = np.ones(image.shape, dtype=np.uint8) * 255 \n",
    "    for contour in contours:\n",
    "        area = cv2.contourArea(contour)\n",
    "        if area < min_area: \n",
    "            cv2.drawContours(mask, [contour], -1, (0, 0, 0), thickness=cv2.FILLED)\n",
    "    result = cv2.bitwise_and(image, mask)\n",
    "    gray_result = cv2.cvtColor(result, cv2.COLOR_BGR2GRAY)\n",
    "    ret, binary_result = cv2.threshold(gray_result, 1, 255, cv2.THRESH_BINARY)\n",
    "    x, y, w, h = cv2.boundingRect(binary_result)\n",
    "    cropped_image = result[y:y+h, x:x+w]\n",
    "    return cropped_image\n",
    "\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        # Define layers: 1 input layer (784 input features), 2 hidden layers, 1 output layer (10 classes)\n",
    "        self.fc1 = nn.Linear(28 * 28, 128)  # 28x28 images flattened to 784 features\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 10)  # 10 output classes (digits 0-9)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28 * 28)  # Flatten the image (batch_size, 28 * 28)\n",
    "        x = F.relu(self.fc1(x))   # Apply ReLU activation after first layer\n",
    "        x = F.relu(self.fc2(x))   # Apply ReLU activation after second layer\n",
    "        x = self.fc3(x)           # Output layer (no activation function for multi-class classification)\n",
    "        return x\n",
    "    \n",
    "def train_mnist(model, train_loader, test_loader, epochs=5, lr=0.001):\n",
    "    # Define loss function and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()  # Suitable for multi-class classification\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)  # Adam optimizer\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(epochs):\n",
    "        model.train()  # Set the model to training mode\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            optimizer.zero_grad()  # Zero the gradients before each batch\n",
    "            output = model(data)   # Forward pass\n",
    "            loss = criterion(output, target)  # Calculate loss\n",
    "            loss.backward()  # Backpropagation\n",
    "            optimizer.step()  # Update model parameters\n",
    "\n",
    "            running_loss += loss.item()  # Accumulate loss\n",
    "            _, predicted = torch.max(output.data, 1)  # Get predicted labels\n",
    "            total += target.size(0)  # Total number of images\n",
    "            correct += (predicted == target).sum().item()  # Correct predictions\n",
    "\n",
    "        # Print statistics for the epoch\n",
    "        print(f'Epoch {epoch + 1}/{epochs}, Loss: {running_loss / len(train_loader):.4f}, Accuracy: {100 * correct / total:.2f}%')\n",
    "\n",
    "        # Evaluate on test data after every epoch\n",
    "        model.eval()  # Set the model to evaluation mode\n",
    "        test_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():  # No need to compute gradients for evaluation\n",
    "            for data, target in test_loader:\n",
    "                output = model(data)  # Forward pass\n",
    "                loss = criterion(output, target)  # Calculate loss\n",
    "                test_loss += loss.item()  # Accumulate loss\n",
    "                _, predicted = torch.max(output.data, 1)  # Get predicted labels\n",
    "                total += target.size(0)  # Total number of images\n",
    "                correct += (predicted == target).sum().item()  # Correct predictions\n",
    "\n",
    "        print(f'Test Loss: {test_loss / len(test_loader):.4f}, Test Accuracy: {100 * correct / total:.2f}%')\n",
    "\n",
    "def train_minst():\n",
    "    transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "    train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "    test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=1000, shuffle=False)\n",
    "\n",
    "    model = SimpleNN()\n",
    "\n",
    "    train_mnist(model, train_loader, test_loader, epochs=5, lr=0.001)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T16:11:13.913331Z",
     "iopub.status.busy": "2024-12-12T16:11:13.913063Z",
     "iopub.status.idle": "2024-12-12T16:11:13.926053Z",
     "shell.execute_reply": "2024-12-12T16:11:13.925294Z",
     "shell.execute_reply.started": "2024-12-12T16:11:13.913304Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def find_largest_component(image):\n",
    "    # Ensure the input image is binary, no need for thresholding\n",
    "    binary = image\n",
    "\n",
    "    # Find connected components and their stats\n",
    "    num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(binary, 8, cv2.CV_32S)\n",
    "\n",
    "    # Find the index of the largest component by area (ignore the background component with label 0)\n",
    "    largest_component_index = 1 + np.argmax(stats[1:, cv2.CC_STAT_AREA])  # Ignore background (label 0)\n",
    "\n",
    "    # Get the bounding box of the largest component\n",
    "    x, y, w, h, area = stats[largest_component_index]\n",
    "\n",
    "    # Crop the image using the bounding box of the largest connected component\n",
    "    cropped_image = image[y:y+h, x:x+w]\n",
    "\n",
    "    return cropped_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T16:11:13.927484Z",
     "iopub.status.busy": "2024-12-12T16:11:13.927095Z",
     "iopub.status.idle": "2024-12-12T16:11:13.940597Z",
     "shell.execute_reply": "2024-12-12T16:11:13.939877Z",
     "shell.execute_reply.started": "2024-12-12T16:11:13.927445Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def get_default_device():\n",
    "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    else:\n",
    "        return torch.device('cpu')\n",
    "    \n",
    "def to_device(data, device):\n",
    "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
    "    if isinstance(data, (list,tuple)):\n",
    "        return [to_device(x, device) for x in data]\n",
    "    return data.to(device, non_blocking=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T16:11:13.943669Z",
     "iopub.status.busy": "2024-12-12T16:11:13.943227Z",
     "iopub.status.idle": "2024-12-12T16:11:13.950655Z",
     "shell.execute_reply": "2024-12-12T16:11:13.949934Z",
     "shell.execute_reply.started": "2024-12-12T16:11:13.943640Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def find_largest_component(image):\n",
    "    # Ensure the input image is binary, no need for thresholding\n",
    "    binary = image\n",
    "\n",
    "    # Find connected components and their stats\n",
    "    num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(binary, 8, cv2.CV_32S)\n",
    "\n",
    "    # Find the index of the largest component by area (ignore the background component with label 0)\n",
    "    largest_component_index = 1 + np.argmax(stats[1:, cv2.CC_STAT_AREA])  # Ignore background (label 0)\n",
    "\n",
    "    # Get the bounding box of the largest component\n",
    "    x, y, w, h, area = stats[largest_component_index]\n",
    "\n",
    "    # Crop the image using the bounding box of the largest connected component\n",
    "    cropped_image = image[y:y+h, x:x+w]\n",
    "\n",
    "    return cropped_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T16:11:13.951856Z",
     "iopub.status.busy": "2024-12-12T16:11:13.951579Z",
     "iopub.status.idle": "2024-12-12T16:11:13.961577Z",
     "shell.execute_reply": "2024-12-12T16:11:13.960924Z",
     "shell.execute_reply.started": "2024-12-12T16:11:13.951831Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def calculate_trend_score(sequence):\n",
    "    sequence = np.array(sequence.copy())\n",
    "    differences = np.diff(sequence)\n",
    "    trend_score = np.sum(np.sign(differences))\n",
    "    return trend_score\n",
    "  \n",
    "def determine_trend(score):\n",
    "    if score > 0:\n",
    "        return \"Increasing\"\n",
    "    else:\n",
    "        return \"Decreasing\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T16:11:13.962888Z",
     "iopub.status.busy": "2024-12-12T16:11:13.962651Z",
     "iopub.status.idle": "2024-12-12T16:11:13.975112Z",
     "shell.execute_reply": "2024-12-12T16:11:13.974384Z",
     "shell.execute_reply.started": "2024-12-12T16:11:13.962864Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def find_cell_color(image, alpha=2):\n",
    "    # Convert to grayscale\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Threshold the grayscale image to create a binary image\n",
    "    ret, binary_thresholded_image = cv2.threshold(gray_image, 127, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    # Calculate the proportion of black pixels\n",
    "    black_pixels = np.sum(binary_thresholded_image == 0)\n",
    "    total_pixels = binary_thresholded_image.size\n",
    "    black_probability = black_pixels / total_pixels\n",
    "    \n",
    "    # If black pixels are over 80%, classify as black\n",
    "    if black_probability > 0.8:\n",
    "        return \"black\"\n",
    "    \n",
    "    # If black pixels are less than 20%, classify as white\n",
    "    elif black_probability < 0.2:\n",
    "        return \"white\"\n",
    "    \n",
    "    # Otherwise, perform the weighted calculation and classify based on the distance\n",
    "    height, width = gray_image.shape\n",
    "    center_x, center_y = width // 2, height // 2\n",
    "    \n",
    "    # Initialize an array to store the weights for each pixel\n",
    "    weights = np.zeros_like(gray_image, dtype=np.float32)\n",
    "    \n",
    "    # Calculate the weights based on distance from the center\n",
    "    for i in range(height):\n",
    "        for j in range(width):\n",
    "            distance = np.sqrt((i - center_y)**2 + (j - center_x)**2)\n",
    "            weights[i, j] = (distance + 1) ** alpha  # Greater distances get exponentially larger weights\n",
    "    \n",
    "    # Normalize the weights to sum to 1\n",
    "    weights /= np.sum(weights)\n",
    "    \n",
    "    # Calculate the weighted sum of the white pixel colors (if they are 255)\n",
    "    weighted_sum = 0\n",
    "    for i in range(height):\n",
    "        for j in range(width):\n",
    "            if binary_thresholded_image[i, j] == 255:  # White pixel in binary image\n",
    "                weighted_sum += weights[i, j]\n",
    "    # print(weighted_sum)\n",
    "    # Classify based on the weighted sum\n",
    "    if weighted_sum > 0.5:  # If white dominates, classify as white\n",
    "        return \"white\"\n",
    "    else:\n",
    "        return \"black\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T16:11:13.976219Z",
     "iopub.status.busy": "2024-12-12T16:11:13.975958Z",
     "iopub.status.idle": "2024-12-12T16:11:13.992258Z",
     "shell.execute_reply": "2024-12-12T16:11:13.991523Z",
     "shell.execute_reply.started": "2024-12-12T16:11:13.976195Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "Board1 = [    ['a8', 'b8', 'c8', 'd8', 'e8', 'f8', 'g8', 'h8'],\n",
    "    ['a7', 'b7', 'c7', 'd7', 'e7', 'f7', 'g7', 'h7'],\n",
    "    ['a6', 'b6', 'c6', 'd6', 'e6', 'f6', 'g6', 'h6'],\n",
    "    ['a5', 'b5', 'c5', 'd5', 'e5', 'f5', 'g5', 'h5'],\n",
    "    ['a4', 'b4', 'c4', 'd4', 'e4', 'f4', 'g4', 'h4'],\n",
    "    ['a3', 'b3', 'c3', 'd3', 'e3', 'f3', 'g3', 'h3'],\n",
    "    ['a2', 'b2', 'c2', 'd2', 'e2', 'f2', 'g2', 'h2'],\n",
    "    ['a1', 'b1', 'c1', 'd1', 'e1', 'f1', 'g1', 'h1']\n",
    "]\n",
    "#vertical:let,dec horizontal:num,asc\n",
    "Board2 = [    ['a1', 'a2', 'a3', 'a4', 'a5', 'a6', 'a7', 'a8'],\n",
    "    ['b1', 'b2', 'b3', 'b4', 'b5', 'b6', 'b7', 'b8'],\n",
    "    ['c1', 'c2', 'c3', 'c4', 'c5', 'c6', 'c7', 'c8'],\n",
    "    ['d1', 'd2', 'd3', 'd4', 'd5', 'd6', 'd7', 'd8'],\n",
    "    ['e1', 'e2', 'e3', 'e4', 'e5', 'e6', 'e7', 'e8'],\n",
    "    ['f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8'],\n",
    "    ['g1', 'g2', 'g3', 'g4', 'g5', 'g6', 'g7', 'g8'],\n",
    "    ['h1', 'h2', 'h3', 'h4', 'h5', 'h6', 'h7', 'h8']\n",
    "]\n",
    "#vertical:num,dec horizontal:let,dec\n",
    "Board3 = [    ['h1', 'g1', 'f1', 'e1', 'd1', 'c1', 'b1', 'a1'],\n",
    "    ['h2', 'g2', 'f2', 'e2', 'd2', 'c2', 'b2', 'a2'],\n",
    "    ['h3', 'g3', 'f3', 'e3', 'd3', 'c3', 'b3', 'a3'],\n",
    "    ['h4', 'g4', 'f4', 'e4', 'd4', 'c4', 'b4', 'a4'],\n",
    "    ['h5', 'g5', 'f5', 'e5', 'd5', 'c5', 'b5', 'a5'],\n",
    "    ['h6', 'g6', 'f6', 'e6', 'd6', 'c6', 'b6', 'a6'],\n",
    "    ['h7', 'g7', 'f7', 'e7', 'd7', 'c7', 'b7', 'a7'],\n",
    "    ['h8', 'g8', 'f8', 'e8', 'd8', 'c8', 'b8', 'a8']\n",
    "]\n",
    "#vertical:let,asc horizontal:num,dec\n",
    "Board4 = [    ['h8', 'h7', 'h6', 'h5', 'h4', 'h3', 'h2', 'h1'],\n",
    "    ['g8', 'g7', 'g6', 'g5', 'g4', 'g3', 'g2', 'g1'],\n",
    "    ['f8', 'f7', 'f6', 'f5', 'f4', 'f3', 'f2', 'f1'],\n",
    "    ['e8', 'e7', 'e6', 'e5', 'e4', 'e3', 'e2', 'e1'],\n",
    "    ['d8', 'd7', 'd6', 'd5', 'd4', 'd3', 'd2', 'd1'],\n",
    "    ['c8', 'c7', 'c6', 'c5', 'c4', 'c3', 'c2', 'c1'],\n",
    "    ['b8', 'b7', 'b6', 'b5', 'b4', 'b3', 'b2', 'b1'],\n",
    "    ['a8', 'a7', 'a6', 'a5', 'a4', 'a3', 'a2', 'a1']\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T16:11:13.993323Z",
     "iopub.status.busy": "2024-12-12T16:11:13.993064Z",
     "iopub.status.idle": "2024-12-12T16:11:14.005589Z",
     "shell.execute_reply": "2024-12-12T16:11:14.004877Z",
     "shell.execute_reply.started": "2024-12-12T16:11:13.993298Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Model(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        super(Model, self).__init__()\n",
    "\n",
    "        self.conv1 = torch.nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = torch.nn.Conv2d(32, 64, 3, 1)\n",
    "        self.dropout1 = torch.nn.Dropout(0.25)\n",
    "        self.dropout2 = torch.nn.Dropout(0.5)\n",
    "        self.fc1 = torch.nn.Linear(9216, 128)\n",
    "        self.fc2 = torch.nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T16:11:14.006588Z",
     "iopub.status.busy": "2024-12-12T16:11:14.006343Z",
     "iopub.status.idle": "2024-12-12T16:11:14.338563Z",
     "shell.execute_reply": "2024-12-12T16:11:14.337774Z",
     "shell.execute_reply.started": "2024-12-12T16:11:14.006564Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "ocr = Model()\n",
    "ocr.load_state_dict(torch.load('/kaggle/input/mn-model/mn.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T16:11:14.340048Z",
     "iopub.status.busy": "2024-12-12T16:11:14.339652Z",
     "iopub.status.idle": "2024-12-12T16:11:14.347203Z",
     "shell.execute_reply": "2024-12-12T16:11:14.346310Z",
     "shell.execute_reply.started": "2024-12-12T16:11:14.340006Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def keep_connected_component(img):\n",
    "    sharp = sharpen_image(img)\n",
    "    _, thresholded = cv2.threshold(sharp, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    thresholded = trim(thresholded)\n",
    "    thresholded = cv2.bitwise_not(thresholded)\n",
    "    \n",
    "    # Detect connected components\n",
    "    num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(thresholded, connectivity=8)\n",
    "    \n",
    "    height, width = thresholded.shape\n",
    "    center = np.array([width // 2, height // 2])\n",
    "    \n",
    "    min_distance = float('inf')\n",
    "    closest_label = None\n",
    "    \n",
    "    # Find the component closest to the center (skipping background label 0)\n",
    "    for i in range(1, num_labels):\n",
    "        component_centroid = centroids[i]\n",
    "        distance = np.linalg.norm(component_centroid - center)\n",
    "        if distance < min_distance:\n",
    "            min_distance = distance\n",
    "            closest_label = i\n",
    "    \n",
    "    # Create a mask for the closest component\n",
    "    mask = np.zeros_like(thresholded, dtype=np.uint8)\n",
    "    \n",
    "    if closest_label is not None:\n",
    "        # Mark the closest component in the mask\n",
    "        mask[labels == closest_label] = 255\n",
    "        \n",
    "        # Get the bounding box of the closest component\n",
    "        x, y, w, h, _ = stats[closest_label]\n",
    "        \n",
    "        # Crop the closest component\n",
    "        cropped_image = thresholded[y:y+h, x:x+w]\n",
    "    else:\n",
    "        # If no component found, return the original thresholded image\n",
    "        cropped_image = thresholded\n",
    "    \n",
    "    return cropped_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T16:11:14.348580Z",
     "iopub.status.busy": "2024-12-12T16:11:14.348323Z",
     "iopub.status.idle": "2024-12-12T16:11:14.365506Z",
     "shell.execute_reply": "2024-12-12T16:11:14.364684Z",
     "shell.execute_reply.started": "2024-12-12T16:11:14.348555Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import cv2\n",
    "\n",
    "def is_empty(image):\n",
    "    return image is None or image.size == 0\n",
    "def is_valid_dict(element, keys):\n",
    "    return isinstance(element, dict) and all(key in element for key in keys)\n",
    "\n",
    "\n",
    "def get_grid_trend(warp, grid):\n",
    "    left = []\n",
    "    right = []\n",
    "    top = []\n",
    "    bottom = []\n",
    "    \n",
    "    if isinstance(grid[0][0], dict):\n",
    "        x1 = int(grid[0][0].get('x', 0) - grid[0][0].get('width', 0) / 2)\n",
    "        y1 = int(grid[0][0].get('y', 0) - grid[0][0].get('height', 0) / 2)\n",
    "    else:\n",
    "        return warp\n",
    "\n",
    "    required_keys = ['x', 'y', 'width', 'height']\n",
    "    \n",
    "    if not is_valid_dict(grid[0][0], required_keys) or not is_valid_dict(grid[-1][-1], required_keys):\n",
    "        return [[],[]]\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    x1 = int(grid[0][0]['x'] - grid[0][0]['width']/2)\n",
    "    y1 = int(grid[0][0]['y'] - grid[0][0]['height']/2)\n",
    "    x2 = int(grid[-1][-1]['x'] + grid[-1][-1]['width']/2)\n",
    "    y2 = int(grid[-1][-1]['y'] + grid[-1][-1]['height']/2)\n",
    "\n",
    "    left = warp[y1:y2, :x1, :]\n",
    "    top = warp[:y1, x1:x2, :]\n",
    "    right = warp[y1:y2, x2:, :]\n",
    "    bottom = warp[y2:, x1:x2, :]\n",
    "    \n",
    "    if is_empty(left) or is_empty(right) or is_empty(top) or is_empty(bottom):\n",
    "        return warp  # or return some default value or handle the case as needed\n",
    "\n",
    "    left = cv2.cvtColor(left, cv2.COLOR_RGB2GRAY)\n",
    "    right = cv2.cvtColor(right, cv2.COLOR_RGB2GRAY)\n",
    "    top = cv2.cvtColor(top, cv2.COLOR_RGB2GRAY)\n",
    "    bottom = cv2.cvtColor(bottom, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    height_vert = int(left.shape[0] / 8)\n",
    "    height_hor = int(top.shape[1] / 8)\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    ocr.to(device)\n",
    "    ocr.eval()\n",
    "\n",
    "    num_left = []\n",
    "    for i in range(8):\n",
    "     \n",
    "        each_part = left[i * height_vert: (i + 1) * height_vert,:]\n",
    "        resized = cv2.resize(each_part, (320, 320), interpolation=cv2.INTER_LINEAR)\n",
    "        # resized = cv2.bitwise_not(resized)\n",
    "        # sharp = sharpen_image(resized)\n",
    "\n",
    "        _, thresholded = cv2.threshold(resized, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "        # contours, _ = cv2.findContours(thresholded, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "            \n",
    "        num =  keep_connected_component(resized)\n",
    "        \n",
    "       \n",
    "        \n",
    "        num = cv2.resize(num, (28, 28), interpolation=cv2.INTER_LINEAR)\n",
    "        \n",
    "        \n",
    "        \n",
    "        num_tensor = torch.tensor(num, dtype=torch.float32)\n",
    "        num_tensor = num_tensor.unsqueeze(0).unsqueeze(0) \n",
    "        num_tensor = num_tensor / 255.0  \n",
    "        \n",
    "        num_tensor = num_tensor.to(device)\n",
    "        \n",
    "        with torch.no_grad(): \n",
    "            result = ocr(num_tensor)\n",
    "\n",
    "        probs = torch.softmax(result, dim=1)\n",
    "\n",
    "        max_prob, preds = torch.max(probs, dim=1)\n",
    "\n",
    "        num_left.append(preds[0].item())\n",
    "                \n",
    "    num_bottom = []\n",
    "    for i in range(8):\n",
    "        \n",
    "        each_part = bottom[:,i * height_hor: (i + 1) * height_hor]\n",
    "        each_part_rotated = np.rot90(each_part, -1)\n",
    "        resized = cv2.resize(each_part_rotated, (320, 320), interpolation=cv2.INTER_LINEAR)\n",
    "        \n",
    "        _, thresholded = cv2.threshold(resized, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "        num = keep_connected_component(thresholded)\n",
    "        \n",
    "        num = cv2.resize(num, (28, 28), interpolation=cv2.INTER_LINEAR)\n",
    "        num_tensor = torch.tensor(num, dtype=torch.float32)\n",
    "        num_tensor = num_tensor.unsqueeze(0).unsqueeze(0) \n",
    "        num_tensor = num_tensor / 255.0  \n",
    "        \n",
    "        contours, hierarchy = cv2.findContours(thresholded, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        cv2.drawContours(thresholded, contours, -1, (0), 1) \n",
    "        num_tensor = num_tensor.to(device)\n",
    "\n",
    "        with torch.no_grad(): \n",
    "            result = ocr(num_tensor)\n",
    "\n",
    "        # Apply softmax to get probabilities\n",
    "        probs = torch.softmax(result, dim=1)\n",
    "\n",
    "        # Get the maximum probability and its corresponding index\n",
    "        max_prob, preds = torch.max(probs, dim=1)\n",
    "\n",
    "        # Only append the prediction if the probability is greater than 0.5\n",
    "        num_bottom.append(preds[0].item())\n",
    "    return [num_left,num_bottom]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T16:11:14.366600Z",
     "iopub.status.busy": "2024-12-12T16:11:14.366354Z",
     "iopub.status.idle": "2024-12-12T16:11:14.378175Z",
     "shell.execute_reply": "2024-12-12T16:11:14.377442Z",
     "shell.execute_reply.started": "2024-12-12T16:11:14.366575Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def get_board_information(image):\n",
    "    board_corners = get_board_corner(image)\n",
    "    warp, perspective_mat = apply_perspective_transform(image, board_corners)\n",
    "    inverse_perspective_mat = np.linalg.inv(perspective_mat)\n",
    "    valid_grid,perspective_grid = get_grid(warp)\n",
    "    original_grid = transform_to_original_grid(perspective_grid, inverse_perspective_mat)\n",
    "    return valid_grid,warp,perspective_grid,original_grid,perspective_mat,inverse_perspective_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T16:11:14.379567Z",
     "iopub.status.busy": "2024-12-12T16:11:14.379252Z",
     "iopub.status.idle": "2024-12-12T16:11:14.391084Z",
     "shell.execute_reply": "2024-12-12T16:11:14.390549Z",
     "shell.execute_reply.started": "2024-12-12T16:11:14.379530Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def map_pieces_to_grid(grid, predictions,labelled_board):\n",
    "\n",
    "    mapped_pieces = {}\n",
    "\n",
    "    for piece in predictions:\n",
    "        piece_x, piece_y = piece[\"x\"], piece[\"y\"]+(piece[\"height\"]/3)\n",
    "        piece_class = piece[\"class_name\"]\n",
    "        # Variables to track the closest square\n",
    "        closest_square = None\n",
    "        min_distance = float(\"inf\")\n",
    "\n",
    "        # Iterate through the grid to find the closest square\n",
    "        for i in range(len(grid)):       # Row index\n",
    "            for j in range(len(grid[i])):  # Column index\n",
    "                square_x = grid[i][j]['x']\n",
    "                square_y = grid[i][j]['y']\n",
    "\n",
    "                # Calculate Euclidean distance between piece and square center\n",
    "                distance = euclidean_distance((piece_x, piece_y), (square_x, square_y))\n",
    "                if distance < min_distance:\n",
    "                    min_distance = distance\n",
    "                    closest_square = labelled_board[i][j]  # Convert indices to square name (1-indexed)\n",
    "\n",
    "        # Map the piece to the closest square\n",
    "        if closest_square:\n",
    "            mapped_pieces[closest_square] = piece_class\n",
    "\n",
    "    return mapped_pieces\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T16:11:14.392126Z",
     "iopub.status.busy": "2024-12-12T16:11:14.391828Z",
     "iopub.status.idle": "2024-12-12T16:11:14.403759Z",
     "shell.execute_reply": "2024-12-12T16:11:14.403137Z",
     "shell.execute_reply.started": "2024-12-12T16:11:14.392100Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def get_labelled_grid(warp,perspective_grid):\n",
    "    num_left,num_bottom = get_grid_trend(warp,perspective_grid)[0], get_grid_trend(warp,perspective_grid)[1]\n",
    "\n",
    "    increase = [1,2,3,4,5,6,7,8]\n",
    "    decrease = [8,7,6,5,4,3,2,1]\n",
    "    \n",
    "    left_increase = sum(1 for i in range(len(num_left)) if num_left[i] == increase[i])\n",
    "    left_decrease = sum(1 for i in range(len(num_left)) if num_left[i] == decrease[i])\n",
    "    bottom_decrease = sum(1 for i in range(len(num_bottom)) if num_bottom[i] == decrease[i])\n",
    "    bottom_increase = sum(1 for i in range(len(num_bottom)) if num_bottom[i] == increase[i])\n",
    "    \n",
    "    max_val = max(left_increase, left_decrease, bottom_decrease, bottom_increase)\n",
    "\n",
    "    print(max_val)\n",
    "    \n",
    "    if(max_val ==0 ):\n",
    "        return Board3\n",
    "    \n",
    "    if(max_val == left_increase):\n",
    "        print(\"Board3\")\n",
    "        return Board3\n",
    "    if(max_val == left_decrease):\n",
    "        print(\"Board1\")\n",
    "        return Board1\n",
    "    if(max_val == bottom_increase):\n",
    "        print(\"Board2\")\n",
    "        return Board2\n",
    "    else:\n",
    "        return Board4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T16:11:14.405018Z",
     "iopub.status.busy": "2024-12-12T16:11:14.404685Z",
     "iopub.status.idle": "2024-12-12T16:11:16.828052Z",
     "shell.execute_reply": "2024-12-12T16:11:16.827271Z",
     "shell.execute_reply.started": "2024-12-12T16:11:14.404963Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model = get_model(\"sp2-ym1iq-9on5y/1\", api_key=\"zZEx3e4qUacIbUbtwsES\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T16:11:16.829241Z",
     "iopub.status.busy": "2024-12-12T16:11:16.828932Z",
     "iopub.status.idle": "2024-12-12T16:11:16.833798Z",
     "shell.execute_reply": "2024-12-12T16:11:16.832957Z",
     "shell.execute_reply.started": "2024-12-12T16:11:16.829213Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def rotation_board(frame,labelled_board):\n",
    "    if (labelled_board == Board1):\n",
    "        return cv2.rotate(frame, cv2.ROTATE_180)\n",
    "    elif (labelled_board == Board2):\n",
    "        return cv2.rotate(frame, cv2.ROTATE_90_CLOCKWISE)\n",
    "    elif (labelled_board == Board4):\n",
    "        return cv2.rotate(frame, cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
    "    else:\n",
    "        return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T16:11:16.835270Z",
     "iopub.status.busy": "2024-12-12T16:11:16.834922Z",
     "iopub.status.idle": "2024-12-12T16:11:16.847874Z",
     "shell.execute_reply": "2024-12-12T16:11:16.847241Z",
     "shell.execute_reply.started": "2024-12-12T16:11:16.835232Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def init_frame(frame):\n",
    "    \n",
    "    resized_frame = trim(frame)\n",
    "    valid_board,warp,perspective_grid,original_grid,perspective_mat,inverse_perspective_mat = get_board_information(resized_frame)\n",
    "    \n",
    "    if(valid_board):\n",
    "        labelled_board = get_labelled_grid(warp,perspective_grid)\n",
    "        resized_frame = rotation_board(resized_frame,labelled_board)\n",
    "        chess_prediction = get_chess_prediction(resized_frame,model)\n",
    "        mapped_pieces = map_pieces_to_grid(original_grid, chess_prediction,Board3)\n",
    "        return mapped_pieces,original_grid,labelled_board\n",
    "    else:\n",
    "        print(\"invalid_board\")\n",
    "        return False,False,False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T16:11:16.849293Z",
     "iopub.status.busy": "2024-12-12T16:11:16.848948Z",
     "iopub.status.idle": "2024-12-12T16:11:16.862533Z",
     "shell.execute_reply": "2024-12-12T16:11:16.861806Z",
     "shell.execute_reply.started": "2024-12-12T16:11:16.849255Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def update_frame(frame,labelled_board,original_grid):\n",
    "    resized_frame = trim(frame)\n",
    "    resized_frame = rotation_board(resized_frame,labelled_board)\n",
    "    chess_prediction = get_chess_prediction(resized_frame,model)\n",
    "    mapped_pieces = map_pieces_to_grid(original_grid, chess_prediction,Board3)\n",
    "    return mapped_pieces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T16:11:16.864326Z",
     "iopub.status.busy": "2024-12-12T16:11:16.864006Z",
     "iopub.status.idle": "2024-12-12T16:11:16.911107Z",
     "shell.execute_reply": "2024-12-12T16:11:16.910144Z",
     "shell.execute_reply.started": "2024-12-12T16:11:16.864289Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class PGNEncoder:\n",
    "    def __init__(self):\n",
    "        self.prev_board = {square: None for square in [f\"{file}{rank}\" for file in \"abcdefgh\" for rank in \"12345678\"]}\n",
    "        self.curr_board = {square: None for square in [f\"{file}{rank}\" for file in \"abcdefgh\" for rank in \"12345678\"]}\n",
    "        self.pgn_moves = []\n",
    "        self.Turns = []  # Keeps track of turns (white or black)\n",
    "        self.black_king_square = \"\"\n",
    "        self.white_king_square = \"\"\n",
    "        self.endgame = False\n",
    "    def initial_board(self, board):\n",
    "        \"\"\"\n",
    "        Set up the initial state of the board.\n",
    "        :param board: A dictionary with keys as square positions and values as piece types (e.g., \"white-pawn\").\n",
    "        \"\"\"\n",
    "        self.prev_board.update(board)\n",
    "        for square in board :\n",
    "            if board[square] == \"black-king\":\n",
    "                self.black_king_square = square\n",
    "                break\n",
    "        for square in board :\n",
    "            if board[square] == \"white-king\":\n",
    "                self.white_king_square = square\n",
    "\n",
    "    def update_board(self, board):\n",
    "        \"\"\"\n",
    "        Update the board state with a new board configuration.\n",
    "        Clears the current board, updates it, and detects moves.\n",
    "        :param board: A dictionary with keys as square positions and values as piece types (e.g., \"white-pawn\").\n",
    "        :return: PGN notation for the detected move or capture.\n",
    "        \"\"\"\n",
    "        # Clear curr_board and update it\n",
    "        self.curr_board = {square: None for square in self.curr_board}\n",
    "        self.curr_board.update(board)\n",
    "\n",
    "        # Detect and record moves\n",
    "        move = self.detect_move()\n",
    "\n",
    "        # Determine the turn based on the moved piece\n",
    "\n",
    "        return move\n",
    "\n",
    "    def detect_move(self):\n",
    "        \"\"\"\n",
    "        Detect moves or captures based on the difference between prev_board and curr_board.\n",
    "        :return: PGN notation for the detected move or capture.\n",
    "        \"\"\"\n",
    "        if (self.endgame):\n",
    "            print(\"game already end\")\n",
    "            return \"valid\"\n",
    "        Missing = []\n",
    "        Move = []\n",
    "        Capture = []\n",
    "        pgn = \"\"\n",
    "        for square in self.prev_board:\n",
    "            prev_piece = self.prev_board[square]\n",
    "            curr_piece = self.curr_board[square]\n",
    "\n",
    "            if prev_piece and not curr_piece:\n",
    "                Missing.append((square, prev_piece))\n",
    "            elif not prev_piece and curr_piece:\n",
    "                Move.append((square, curr_piece))\n",
    "            elif prev_piece and curr_piece and prev_piece != curr_piece:\n",
    "                Capture.append((square, prev_piece, curr_piece))\n",
    "\n",
    "        if len(Move) > 1 or len(Missing) > 1:\n",
    "            print(\"Ambiguous move detected!\")\n",
    "            return \"Ambiguous\"\n",
    "        \n",
    "        if Missing and Move:\n",
    "            move_square, curr_piece = Move[0]\n",
    "            miss_square, miss_piece = Missing[0]\n",
    "            if miss_piece == curr_piece and miss_square != move_square and self.is_valid_move(curr_piece,miss_square,move_square):\n",
    "                # Update prev_board\n",
    "                self.prev_board[miss_square] = None\n",
    "                self.prev_board[move_square] = curr_piece\n",
    "                    \n",
    "                if curr_piece == \"black-king\" :\n",
    "                    self.black_king_square = move_square\n",
    "                elif curr_piece == \"white-king\" :\n",
    "                    self.white_king_square = move_square\n",
    "\n",
    "                # Generate PGN for move\n",
    "                pgn = self.generate_pgn_move(miss_piece, miss_square, move_square, captured_piece=None)\n",
    "                self.pgn_moves.append(pgn)\n",
    "\n",
    "                #Update Turns\n",
    "                piece_color = \"white\" if \"white\" in curr_piece else \"black\"\n",
    "                self.Turns.append(piece_color)\n",
    "                \n",
    "                \n",
    "\n",
    "        elif Missing and Capture:\n",
    "            miss_square, miss_piece = Missing[0]\n",
    "            capture_square, prev_piece, curr_piece = Capture[0]\n",
    "            if miss_piece == curr_piece and capture_square != miss_square and self.is_valid_move(curr_piece,miss_square,capture_square):\n",
    "                \n",
    "                #Update Turns\n",
    "                piece_color = \"white\" if \"white\" in curr_piece else \"black\"\n",
    "                self.Turns.append(piece_color)\n",
    "\n",
    "                # Update prev_board\n",
    "                self.prev_board[miss_square] = None\n",
    "                self.prev_board[capture_square] = curr_piece\n",
    "                if curr_piece == \"black-king\" :\n",
    "                    self.black_king_square = capture_square\n",
    "                elif curr_piece == \"white-king\" :\n",
    "                    self.white_king_square = capture_square \n",
    "                # Generate PGN for capture\n",
    "\n",
    "                pgn = self.generate_pgn_move(miss_piece, miss_square, capture_square, captured_piece=prev_piece)\n",
    "                self.pgn_moves.append(pgn)\n",
    "                \n",
    "        return \"valid\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_piece_notation(piece):\n",
    "        \"\"\"\n",
    "        Returns the PGN notation for the given piece type.\n",
    "        \"\"\"\n",
    "        if \"pawn\" in piece:\n",
    "            return \"\"\n",
    "        elif \"knight\" in piece:\n",
    "            return \"N\"\n",
    "        elif \"bishop\" in piece:\n",
    "            return \"B\"\n",
    "        elif \"rook\" in piece:\n",
    "            return \"R\"\n",
    "        elif \"queen\" in piece:\n",
    "            return \"Q\"\n",
    "        elif \"king\" in piece:\n",
    "            return \"K\"\n",
    "        return \"\"\n",
    "\n",
    "    def generate_pgn_move(self, piece, start_square, end_square, captured_piece=None):\n",
    "        \"\"\"\n",
    "        Generate PGN notation for a move or capture.\n",
    "        :param piece: The piece making the move (e.g., \"white-pawn\").\n",
    "        :param start_square: The starting square of the piece (e.g., \"d5\").\n",
    "        :param end_square: The destination square of the piece (e.g., \"e6\").\n",
    "        :param captured_piece: The captured piece, or None if it's not a capture.\n",
    "        :return: A string in PGN notation.\n",
    "        \"\"\"\n",
    "        piece_letter = self.get_piece_notation(piece.split(\"-\")[1])\n",
    "        capture_marker = \"x\" if captured_piece else \"\"\n",
    "        check = self.can_attack_king(end_square)\n",
    "        check_mate = False\n",
    "        \n",
    "        if check :\n",
    "            if \"white\" in piece :\n",
    "                check_mate =  self.check_king_status(self.black_king_square)\n",
    "            else :\n",
    "                check_mate =  self.check_king_status(self.white_king_square)\n",
    "                \n",
    "        if check and check_mate:\n",
    "            check_marker = \"#\"\n",
    "            self.endgame = True\n",
    "        elif check:\n",
    "            check_marker = \"+\"\n",
    "        else:\n",
    "            check_marker = \"\"\n",
    "\n",
    "        if \"pawn\" in piece and captured_piece:\n",
    "            # For pawn captures, include the file (a-h) of the starting square\n",
    "            file_from = start_square[0]\n",
    "            return f\"{file_from}{capture_marker}{end_square}{check_marker}\"\n",
    "        elif captured_piece:\n",
    "            # For captures involving other pieces, include the captured piece's type\n",
    "            captured_letter = self.get_piece_notation(captured_piece.split(\"-\")[1])\n",
    "            return f\"{piece_letter}{capture_marker}{end_square}{check_marker}\"\n",
    "        else:\n",
    "            # For non-capture moves\n",
    "            return f\"{piece_letter}{end_square}{check_marker}\"\n",
    "            \n",
    "    def position_to_coordinates(self,position):\n",
    "        col, row = position\n",
    "        return int(row) - 1, ord(col) - ord('a')\n",
    "        \n",
    "    # แปลงพิกัด (row, col) กลับเป็นตำแหน่ง เช่น \"d4\"\n",
    "    def coordinates_to_position(self,row, col):\n",
    "        return f\"{chr(col + ord('a'))}{row + 1}\"\n",
    "        \n",
    "    def can_attack_king(self, square):\n",
    "    \n",
    "        piece = self.prev_board[square]  # หาหมากในตำแหน่ง square\n",
    "        if not piece:\n",
    "            return False  # ไม่มีหมากในตำแหน่งนี้\n",
    "\n",
    "        # หาตำแหน่งคิงฝั่งตรงข้าม\n",
    "        if \"white\" in piece:\n",
    "            target_king_square = self.black_king_square\n",
    "        elif \"black\" in piece:\n",
    "            target_king_square = self.white_king_square\n",
    "        else:\n",
    "            return False  # ไม่ใช่หมากที่รู้จัก\n",
    "\n",
    "        piece_type = piece.split(\"-\")[1]  # ชนิดหมาก เช่น \"queen\", \"pawn\"\n",
    "\n",
    "        # แปลงตำแหน่งเช่น \"d4\" เป็นพิกัด (row, col)\n",
    "        def position_to_coordinates(position):\n",
    "            col, row = position\n",
    "            return int(row) - 1, ord(col) - ord('a')\n",
    "\n",
    "        # แปลงพิกัด (row, col) กลับเป็นตำแหน่ง เช่น \"d4\"\n",
    "        def coordinates_to_position(row, col):\n",
    "            return f\"{chr(col + ord('a'))}{row + 1}\"\n",
    "\n",
    "        # ตรวจสอบเส้นทางว่ามีสิ่งกีดขวางหรือไม่\n",
    "        def is_path_clear(start, end, direction):\n",
    "            row, col = start\n",
    "            end_row, end_col = end\n",
    "\n",
    "            while (row, col) != (end_row, end_col):\n",
    "                row += direction[0]\n",
    "                col += direction[1]\n",
    "                # ตรวจสอบว่าตำแหน่งอยู่ในกระดาน\n",
    "                if not (0 <= row <= 7 and 0 <= col <= 7):\n",
    "                    return False  # ถ้าตำแหน่งอยู่นอกกระดาน ให้ถือว่าไม่มีเส้นทาง\n",
    "\n",
    "                pos = coordinates_to_position(row, col)\n",
    "                \n",
    "                if pos != coordinates_to_position(end_row, end_col) and self.prev_board.get(pos) is not None:\n",
    "                    return False  # มีสิ่งกีดขวาง\n",
    "            return True\n",
    "\n",
    "        # แปลงตำแหน่งหมากและคิงเป็นพิกัด\n",
    "        piece_row, piece_col = position_to_coordinates(square)\n",
    "        king_row, king_col = position_to_coordinates(target_king_square)\n",
    "        row_diff, col_diff = king_row - piece_row, king_col - piece_col\n",
    "\n",
    "        # ตรวจสอบการเดินของหมากแต่ละประเภท\n",
    "        if piece_type == \"queen\":\n",
    "            # Queen: เดินได้ทั้งแนวตรงและแนวทแยง\n",
    "            if piece_row == king_row or piece_col == king_col:  # แนวตรง\n",
    "                direction = (0, 1 if row_diff > 0 else -1) if piece_row == king_row else (1 if row_diff > 0 else -1, 0)\n",
    "                return is_path_clear((piece_row, piece_col), (king_row, king_col), direction)\n",
    "            if abs(row_diff) == abs(col_diff):  # แนวทแยง\n",
    "                direction = (1 if row_diff > 0 else -1, 1 if col_diff > 0 else -1)\n",
    "                return is_path_clear((piece_row, piece_col), (king_row, king_col), direction)\n",
    "\n",
    "        elif piece_type == \"rook\":\n",
    "            # Rook: เดินได้เฉพาะแนวตรง\n",
    "            if piece_row == king_row or piece_col == king_col:\n",
    "                direction = (0, 1) if piece_row == king_row else (1 if row_diff > 0 else -1, 0)\n",
    "                return is_path_clear((piece_row, piece_col), (king_row, king_col), direction)\n",
    "\n",
    "        elif piece_type == \"bishop\":\n",
    "            # Bishop: เดินได้เฉพาะแนวทแยง\n",
    "            if abs(row_diff) == abs(col_diff):\n",
    "                direction = (1 if row_diff > 0 else -1, 1 if col_diff > 0 else -1)\n",
    "                return is_path_clear((piece_row, piece_col), (king_row, king_col), direction)\n",
    "\n",
    "        elif piece_type == \"knight\":\n",
    "            # Knight: เดินเป็นรูปตัว L\n",
    "            return (abs(row_diff), abs(col_diff)) in [(2, 1), (1, 2)]\n",
    "\n",
    "        elif piece_type == \"pawn\":\n",
    "            # Pawn: เดินเฉพาะแนวเฉียง 1 ช่องเพื่อกินหมาก\n",
    "            direction = 1 if \"white\" in piece else -1  # white เดินขึ้น (-1), black เดินลง (+1)\n",
    "            return (row_diff, col_diff) in [(direction, 1), (direction, -1)]\n",
    "\n",
    "        elif piece_type == \"king\":\n",
    "            # King: เดินได้ทุกทิศทาง 1 ช่อง\n",
    "            return abs(row_diff) <= 1 and abs(col_diff) <= 1\n",
    "\n",
    "        return False  # ไม่ใช่หมากที่รู้จักหรือไม่สามารถรุกได้\n",
    "        \n",
    "    def check_king_status(self, king_square):\n",
    "        \"\"\"\n",
    "        ตรวจสอบว่าคิงที่ถูกโจมตีสามารถหลบหนีได้หรือไม่\n",
    "        \"\"\"\n",
    "        king_moves = [\n",
    "            (1, 0), (-1, 0), (0, 1), (0, -1), (1, 1), (1, -1), (-1, 1), (-1, -1)\n",
    "        ]\n",
    "        king_row, king_col = self.position_to_coordinates(king_square)\n",
    "    \n",
    "        for move in king_moves:\n",
    "            new_row, new_col = king_row + move[0], king_col + move[1]\n",
    "            if 0 <= new_row <= 7 and 0 <= new_col <= 7:  # ตรวจสอบว่าอยู่ในกระดาน\n",
    "                new_square = self.coordinates_to_position(new_row, new_col)\n",
    "                if self.prev_board[new_square] is None or self.is_valid_move(\"king\", king_square, new_square):\n",
    "                    if not any(self.can_attack_king(new_square) for square in self.prev_board):\n",
    "                        return False  # มีตำแหน่งที่คิงสามารถหนีได้\n",
    "    \n",
    "        return True  # คิงไม่มีที่หนี\n",
    "    \n",
    "    def is_valid_move(self, piece, start_square, end_square):\n",
    "        \"\"\"\n",
    "        ตรวจสอบว่าการเดินหมากเป็นตาที่ถูกต้องตามกติกาหรือไม่\n",
    "        Arguments:\n",
    "            - piece: หมากที่กำลังเดิน (ตัวอย่าง: \"white-pawn\")\n",
    "            - start_square: ตำแหน่งเริ่มต้น (ตัวอย่าง: \"e2\")\n",
    "            - end_square: ตำแหน่งปลายทาง (ตัวอย่าง: \"e4\")\n",
    "        Returns:\n",
    "            - True: ถ้าการเดินนี้ถูกต้อง\n",
    "            - False: ถ้าการเดินนี้ไม่ถูกต้อง\n",
    "        \"\"\"\n",
    "        if piece is None or self.prev_board[start_square] != piece:\n",
    "            return False  # ไม่ใช่ตำแหน่งของหมากที่กำลังเดิน\n",
    "\n",
    "        # แยกประเภทและสีของหมาก\n",
    "        piece_type = piece.split(\"-\")[1]\n",
    "        piece_color = piece.split(\"-\")[0]\n",
    "\n",
    "        # แปลงตำแหน่ง เช่น \"e2\" เป็นพิกัด (row, col)\n",
    "        def position_to_coordinates(position):\n",
    "            col, row = position\n",
    "            return int(row) - 1, ord(col) - ord('a')\n",
    "        \n",
    "        # แปลงพิกัด (row, col) กลับเป็นตำแหน่ง เช่น \"d4\"\n",
    "        def coordinates_to_position(row, col):\n",
    "            return f\"{chr(col + ord('a'))}{row + 1}\"\n",
    "        # ตรวจสอบเส้นทางว่าไม่มีสิ่งกีดขวาง\n",
    "        def is_path_clear(start, end, direction):\n",
    "            row, col = start\n",
    "            end_row, end_col = end\n",
    "\n",
    "            while (row, col) != (end_row, end_col):\n",
    "                row += direction[0]\n",
    "                col += direction[1]\n",
    "                \n",
    "                # ตรวจสอบว่าตำแหน่งอยู่ในกระดาน\n",
    "                if not (0 <= row <= 7 and 0 <= col <= 7):\n",
    "                    return False  # ถ้าตำแหน่งอยู่นอกกระดาน ให้ถือว่าไม่มีเส้นทาง\n",
    "\n",
    "                pos = coordinates_to_position(row, col)\n",
    "                \n",
    "                if pos != coordinates_to_position(end_row, end_col) and self.prev_board.get(pos) is not None:\n",
    "                    return False  # มีสิ่งกีดขวาง\n",
    "            return True\n",
    "\n",
    "\n",
    "        # ตรวจสอบว่าตำแหน่งอยู่ในกระดาน\n",
    "        def is_within_board(position):\n",
    "            row, col = position\n",
    "            return 0 <= row <= 7 and 0 <= col <= 7\n",
    "\n",
    "        # ตรวจสอบหมากฝ่ายตรงข้าม\n",
    "        def is_opponent_piece(piece, target_square):\n",
    "            target_piece = self.prev_board.get(target_square)\n",
    "            return target_piece is not None and piece.split(\"-\")[0] != target_piece.split(\"-\")[0]\n",
    "\n",
    "        # แปลงตำแหน่ง start และ end เป็นพิกัด\n",
    "        start_row, start_col = position_to_coordinates(start_square)\n",
    "        end_row, end_col = position_to_coordinates(end_square)\n",
    "        row_diff, col_diff = end_row - start_row, end_col - start_col\n",
    "\n",
    "        # ตรวจสอบว่าตำแหน่งอยู่ในกระดาน\n",
    "        if not is_within_board((start_row, start_col)) or not is_within_board((end_row, end_col)):\n",
    "            return False\n",
    "\n",
    "        # ตรวจสอบการเดินสำหรับหมากแต่ละประเภท\n",
    "        if piece_type == \"pawn\":\n",
    "            # return True\n",
    "            # Pawn: เดินได้ 1 ช่อง (หรือ 2 ช่องถ้าตำแหน่งเริ่มต้น) และกินเฉียง\n",
    "            direction = 1 if piece_color == \"white\" else -1  # white เดินขึ้น (+1), black เดินลง (-1)\n",
    "            if self.prev_board[end_square] is None:  # เดินแบบไม่กิน\n",
    "                if col_diff == 0 and row_diff == direction:\n",
    "                    return True\n",
    "                if col_diff == 0 and row_diff == 2 * direction and 1 <= start_row <= 6:  # เดิน 2 ช่องจากตำแหน่งเริ่มต้น and start_row in (1, 6)\n",
    "                    return is_path_clear((start_row, start_col), (end_row, end_col), (direction, 0))\n",
    "            elif is_opponent_piece(piece, end_square):  # เดินแบบกิน\n",
    "                return (row_diff, col_diff) in [(direction, 1), (direction, -1)]\n",
    "\n",
    "        elif piece_type == \"rook\":\n",
    "            # Rook: เดินเฉพาะแนวตรง\n",
    "            if start_row == end_row or start_col == end_col:\n",
    "                direction = (0, 1 if col_diff > 0 else -1) if start_row == end_row else (1 if row_diff > 0 else -1, 0)\n",
    "                return is_path_clear((start_row, start_col), (end_row, end_col), direction)\n",
    "\n",
    "        elif piece_type == \"bishop\":\n",
    "            # Bishop: เดินเฉพาะแนวทแยง\n",
    "            if abs(row_diff) == abs(col_diff):\n",
    "                direction = (1 if row_diff > 0 else -1, 1 if col_diff > 0 else -1)\n",
    "                return is_path_clear((start_row, start_col), (end_row, end_col), direction)\n",
    "\n",
    "        elif piece_type == \"queen\":\n",
    "            # Queen: เดินได้ทั้งแนวตรงและแนวทแยง\n",
    "            if start_row == end_row or start_col == end_col:  # แนวตรง\n",
    "                direction = (0, 1 if col_diff > 0 else -1) if start_row == end_row else (1 if row_diff > 0 else -1, 0)\n",
    "                return is_path_clear((start_row, start_col), (end_row, end_col), direction)\n",
    "            if abs(row_diff) == abs(col_diff):  # แนวทแยง\n",
    "                direction = (1 if row_diff > 0 else -1, 1 if col_diff > 0 else -1)\n",
    "                return is_path_clear((start_row, start_col), (end_row, end_col), direction)\n",
    "\n",
    "        elif piece_type == \"knight\":\n",
    "            # Knight: เดินเป็นรูปตัว L\n",
    "            return (abs(row_diff), abs(col_diff)) in [(2, 1), (1, 2)] and (\n",
    "                self.prev_board[end_square] is None or is_opponent_piece(piece, end_square))\n",
    "\n",
    "        elif piece_type == \"king\":\n",
    "            # King: เดินได้ทุกทิศทาง 1 ช่อง\n",
    "            return abs(row_diff) <= 1 and abs(col_diff) <= 1 and (\n",
    "                self.prev_board[end_square] is None or is_opponent_piece(piece, end_square))\n",
    "\n",
    "        return False  # ไม่ใช่หมากที่รู้จักหรือการเดินไม่ถูกต้อง\n",
    "        \n",
    "    def print_pgn_format(self):\n",
    "        \"\"\"\n",
    "        Print the PGN format of the game based on the recorded moves and turns.\n",
    "        \"\"\"\n",
    "        PGN = \"\"\n",
    "        current_turn = 1\n",
    "        \n",
    "        if len(self.Turns) == 0:\n",
    "            return PGN\n",
    "        \n",
    "        # Start with the first player's move\n",
    "        FirstPlayer = self.Turns[0]\n",
    "        \n",
    "        # Check the first move, if the first player is black, we start with \"1...\". Otherwise, \"1.\"\n",
    "        if FirstPlayer != \"white\":\n",
    "            PGN = \"1. ... \"\n",
    "            current_turn += 1 \n",
    "        i = 0\n",
    "        while i < len(self.pgn_moves):\n",
    "            move = self.pgn_moves[i]\n",
    "            if i > 1 and i + 2 < len(self.pgn_moves) and self.Turns[i] == self.Turns[i+1] and self.pgn_moves[i][0] ==  self.pgn_moves[i+1][0]:\n",
    "                print(\"illegal move\")\n",
    "                i += 2\n",
    "                continue\n",
    "                \n",
    "            # Add moves based on the current player's turn\n",
    "            if self.Turns[i] == \"white\":\n",
    "                PGN += f\"{current_turn}. \" + move + \" \"\n",
    "                current_turn += 1  # Increment turn after the white player's move\n",
    "            else:\n",
    "                PGN += move + \" \"  # Black player's move, no need to add turn number\n",
    "            i += 1    \n",
    "        return PGN.strip()\n",
    "\n",
    "\n",
    "    def end(self):\n",
    "        \"\"\"\n",
    "        End the game and print the PGN format.\n",
    "        \"\"\"\n",
    "        print(self.print_pgn_format())\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-12T16:11:16.912941Z",
     "iopub.status.busy": "2024-12-12T16:11:16.912335Z",
     "iopub.status.idle": "2024-12-12T16:11:16.933043Z",
     "shell.execute_reply": "2024-12-12T16:11:16.932214Z",
     "shell.execute_reply.started": "2024-12-12T16:11:16.912897Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "starter_board = {\n",
    "    \"a1\": \"white-rook\",\n",
    "    \"b1\": \"white-knight\",\n",
    "    \"c1\": \"white-bishop\",\n",
    "    \"d1\": \"white-queen\",\n",
    "    \"e1\": \"white-king\",\n",
    "    \"f1\": \"white-bishop\",\n",
    "    \"g1\": \"white-knight\",\n",
    "    \"h1\": \"white-rook\",\n",
    "\n",
    "    \"a2\": \"white-pawn\",\n",
    "    \"b2\": \"white-pawn\",\n",
    "    \"c2\": \"white-pawn\",\n",
    "    \"d2\": \"white-pawn\",\n",
    "    \"e2\": \"white-pawn\",\n",
    "    \"f2\": \"white-pawn\",\n",
    "    \"g2\": \"white-pawn\",\n",
    "    \"h2\": \"white-pawn\",\n",
    "\n",
    "    \"a7\": \"black-pawn\",\n",
    "    \"b7\": \"black-pawn\",\n",
    "    \"c7\": \"black-pawn\",\n",
    "    \"d7\": \"black-pawn\",\n",
    "    \"e7\": \"black-pawn\",\n",
    "    \"f7\": \"black-pawn\",\n",
    "    \"g7\": \"black-pawn\",\n",
    "    \"h7\": \"black-pawn\",\n",
    "\n",
    "    \"a8\": \"black-rook\",\n",
    "    \"b8\": \"black-knight\",\n",
    "    \"c8\": \"black-bishop\",\n",
    "    \"d8\": \"black-queen\",\n",
    "    \"e8\": \"black-king\",\n",
    "    \"f8\": \"black-bishop\",\n",
    "    \"g8\": \"black-knight\",\n",
    "    \"h8\": \"black-rook\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import csv\n",
    "\n",
    "# Define video paths directly\n",
    "video_paths = {\n",
    "    \"2_Move_rotate_student.mp4\": \"/kaggle/input/cu-chess-detection/Chess Detection Competition/test_videos/2_Move_rotate_student.mp4\",\n",
    "    \"2_move_student.mp4\": \"/kaggle/input/cu-chess-detection/Chess Detection Competition/test_videos/2_move_student.mp4\",\n",
    "    \"4_Move_studet.mp4\": \"/kaggle/input/cu-chess-detection/Chess Detection Competition/test_videos/4_Move_studet.mp4\",\n",
    "    \"6_Move_student.mp4\": \"/kaggle/input/cu-chess-detection/Chess Detection Competition/test_videos/6_Move_student.mp4\",\n",
    "    \"8_Move_student.mp4\": \"/kaggle/input/cu-chess-detection/Chess Detection Competition/test_videos/8_Move_student.mp4\",\n",
    "    \"(Bonus)Long_video_student.mp4\": \"/kaggle/input/cu-chess-detection/Chess Detection Competition/bonus_video/Bonus Long Video Label.mp4\"\n",
    "}\n",
    "\n",
    "# Define output folder and CSV file\n",
    "output_folder = \"/kaggle/working/\"  # Folder for outputs\n",
    "csv_file = os.path.join(output_folder, \"submission.csv\")\n",
    "\n",
    "# Create and initialize the CSV file with default values\n",
    "with open(csv_file, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    # Write header\n",
    "    writer.writerow([\"row_id\", \"output\"])\n",
    "    # Write initial rows with default output\n",
    "    for video_name in video_paths.keys():\n",
    "        writer.writerow([video_name, \"1. \"])\n",
    "\n",
    "# Process videos and update the CSV\n",
    "with open(csv_file, mode='r+', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    existing_rows = {row[0]: row[1] for row in csv.reader(file)}  # Track existing rows\n",
    "\n",
    "    for video_name, video_path in video_paths.items():\n",
    "        # Default output value\n",
    "        result = \"1. \"\n",
    "\n",
    "        if os.path.exists(video_path):\n",
    "            print(f\"Processing video: {video_name}\")\n",
    "\n",
    "            # Open video file\n",
    "            cap = cv2.VideoCapture(video_path)\n",
    "            if not cap.isOpened():\n",
    "                print(f\"Error: Could not open video file {video_path}\")\n",
    "                continue\n",
    "            processed_count = 0\n",
    "            frame_count = 0\n",
    "            frame_interval = 50  # Analyze every 100th frame\n",
    "            start = False\n",
    "            state = \"valid\"\n",
    "            # Initialize the PGN encoder\n",
    "            pgn_encoder = PGNEncoder()\n",
    "            Ambiguous_count = 0\n",
    "            while cap.isOpened():\n",
    "                if (video_name != \"(Bonus)Long_video_student.mp4\"):\n",
    "                    if state == \"valid\":\n",
    "                        frame_interval = 50\n",
    "                    else:\n",
    "                        frame_interval = 5\n",
    "                        \n",
    "                    ret, frame = cap.read()\n",
    "                    if not ret:\n",
    "                        # Video ends, finalize the PGN result\n",
    "                        result = pgn_encoder.print_pgn_format()\n",
    "                        pgn_encoder.end()\n",
    "                        break\n",
    "                    \n",
    "                    # Process every `frame_interval`-th frame\n",
    "                    if frame_count % frame_interval == 0:\n",
    "                        # Chessboard processing\n",
    "                        if not start:\n",
    "                            initial_board, original_grid, labelled_board = init_frame(frame)  # Replace with detected board state\n",
    "                            if initial_board:\n",
    "                                start = True\n",
    "                                pgn_encoder.initial_board(initial_board)\n",
    "                                \n",
    "                        else:\n",
    "                            #Detect Hand\n",
    "                            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                            results = hands.process(frame_rgb)\n",
    "                            if results.multi_hand_landmarks:\n",
    "                                print(\"Hand detected!\")\n",
    "                                state = \"invalid\"\n",
    "                                frame_count += 1\n",
    "                                continue\n",
    "                                \n",
    "                            state = \"valid\"\n",
    "                            updated_board = update_frame(frame, labelled_board, original_grid)  # Replace with detected board state\n",
    "                            state = pgn_encoder.update_board(updated_board)\n",
    "                        processed_count += 1\n",
    "                    frame_count += 1\n",
    "                ############################################################################################################################\n",
    "                else:\n",
    "                    if state == \"valid\":\n",
    "                        print(\"valid!\")\n",
    "                        frame_interval = 50\n",
    "                        Ambiguous_count = 0\n",
    "                    elif state == \"Ambiguous\" :\n",
    "                        frame_interval = 10\n",
    "                        Ambiguous_count += 1\n",
    "                    else:\n",
    "                        frame_interval = 10\n",
    "                    ret, frame = cap.read()    \n",
    "                    current_pos = cap.get(cv2.CAP_PROP_POS_FRAMES)  # Get the current frame index\n",
    "                    cap.set(cv2.CAP_PROP_POS_FRAMES, current_pos + frame_interval)\n",
    "                    \n",
    "                    if not ret:\n",
    "                        # Video ends, finalize the PGN result\n",
    "                        result = pgn_encoder.print_pgn_format()\n",
    "                        pgn_encoder.end()\n",
    "                        break\n",
    "                    \n",
    "                    # Process every `frame_interval`-th frame\n",
    "                    # Chessboard processing\n",
    "                    if not start:\n",
    "                        current_pos = cap.get(cv2.CAP_PROP_POS_FRAMES)  # Get the current frame index\n",
    "                        cap.set(cv2.CAP_PROP_POS_FRAMES, 20)\n",
    "                        ret, frame = cap.read()\n",
    "                        initial_board, original_grid, labelled_board = init_frame(frame)  # Replace with detected board state\n",
    "                        if initial_board:\n",
    "                            start = True\n",
    "                            pgn_encoder.initial_board(initial_board)\n",
    "                           \n",
    "                                \n",
    "                    else:\n",
    "                        #Detect Hand\n",
    "                        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                        results = hands.process(frame_rgb)\n",
    "                        if results.multi_hand_landmarks:\n",
    "                            print(\"Hand detected!\")\n",
    "                            state = \"invalid\"\n",
    "                            frame_count += 1\n",
    "                            continue\n",
    "                        \n",
    "                        if (Ambiguous_count > 70):\n",
    "                            current_pos = cap.get(cv2.CAP_PROP_POS_FRAMES)  # Get the current frame index\n",
    "                            cap.set(cv2.CAP_PROP_POS_FRAMES, current_pos - 100)\n",
    "                            ret, frame = cap.read()\n",
    "                            while True :\n",
    "                                frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                                results = hands.process(frame_rgb)\n",
    "                                if results.multi_hand_landmarks:\n",
    "                                    current_pos = cap.get(cv2.CAP_PROP_POS_FRAMES)  # Get the current frame index\n",
    "                                    cap.set(cv2.CAP_PROP_POS_FRAMES, current_pos - 10)\n",
    "                                    ret, frame = cap.read()\n",
    "                                    print(\"Hand detected!\")\n",
    "                                else:\n",
    "                                    break\n",
    "                            updated_board = update_frame(frame, labelled_board, original_grid)  # Replace with detected board state\n",
    "                            pgn_encoder.initial_board(updated_board)\n",
    "                            state = \"valid\"\n",
    "                        else:\n",
    "                            updated_board = update_frame(frame, labelled_board, original_grid)  # Replace with detected board state\n",
    "                            state = pgn_encoder.update_board(updated_board)\n",
    "                    processed_count += 1\n",
    "                # if (video_name == \"(Bonus)Long_video_student.mp4\") and processed_count > 200 :\n",
    "                #     result = pgn_encoder.print_pgn_format()\n",
    "                #     pgn_encoder.end()\n",
    "                #     break\n",
    "            # Release the video file\n",
    "            cap.release()\n",
    "            print(f\"Finished processing: {video_name}\")\n",
    "\n",
    "        if not result:\n",
    "            result = \"1. \"  # Default if no result was generated\n",
    "\n",
    "        # Update the output value in the CSV\n",
    "        existing_rows[video_name] = result\n",
    "\n",
    "    # Rewrite the CSV file with updated results\n",
    "    file.seek(0)  # Move to the beginning\n",
    "    for row_id, output in existing_rows.items():\n",
    "        writer.writerow([row_id, output])\n",
    "\n",
    "print(f\"All videos processed. Results saved in {csv_file}.\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 10486124,
     "sourceId": 83828,
     "sourceType": "competition"
    },
    {
     "datasetId": 6274270,
     "sourceId": 10160936,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6275695,
     "sourceId": 10162822,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30804,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
